{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection using a Variational Auto-Encoder\n",
    "In this project, we are using a Variational Auto-Encoder (VAE) to detect anomalies in a timeseries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to VAEs in Anomaly Detection\n",
    "### 1.1 What is a VAE?\n",
    "VAEs are a class of generative models that learn a compressed latent representation of the data. Intuitively, they learn the inherent structure of the data, so that it can be reconstructed just by providing a few values. As an analogy, imagine that you were asked to describe any object to someone just from basic shapes, so that they can draw it. It would take ages to explain everything in enough detail. Now, imaging you can tell them the object is in fact a dog. Immediately, it becomes much easier to explain, and within a few minutes, you should be able to give a pretty accurate description of the dog. This is because you and your friend share a common knowledge of what constitutes a dog and what distinguishes one dog from another. With this pre-learned knowledge, the description of the object becomes much more compact. \n",
    "\n",
    "To learn this structure, the VAE has two parts: An encoder and a decoder. The compact representation (the \"latent vector\") is sandwiched between these two parts. During training, we present the encoder with data samples that it converts into latent vectors. Then the decoder takes the latent vectors and tries to reconstruct the data samples. By minimising the recontruction error (plus a regularisation loss, more on that later), the encoder gets better at compressing the data into a meaningful latent vector, and the decoder becomes better at converting this latent vector into plausible reconstructed samples.\n",
    "\n",
    "However, we also need to make sure that the VAE is able to reconstruct samples outside of the training set, i.e. to generalise. This is achieved by penalising (\"regularising\") the reconstruction loss with an additional term, the Kullback-Leibler Divergence. In broad terms, this ensures that the VAE learns the distribution of the data, rather than the datapoints themselves. There is much more to the theory of VAEs (e.g. the \"reparameterisation trick\") but this is outside the scope of this notebook. You can learn a lot more about VAEs [here](https://arxiv.org/abs/1606.05908) \\[1\\].\n",
    "\n",
    "### 1.2 Why use a VAE in Anomaly Detection?\n",
    "\n",
    "The idea behind Anomaly Detection is to detect samples that are far from what is usually seen, in some sense or other. The definition of \"far\" is the difficult bit. In simple, one-dimensional cases, we could just look at the value tracked over time and decide that extreme values are anomalies. Lots of methods use this idea in more or less sophisticated ways.\n",
    "\n",
    "However, things become trickier in higher-dimensional spaces where variables interact with each other or are correlated in some non-obvious ways. Sure, a sheep is \"far\" from a dog, but how do you formalise this distance? Its size is clearly not enough: some dogs are as big or larger than sheeps. Colour doesn't work either -- there are black sheeps and white dogs. Ear shape -- let's not even get there. The decision will clearly require a combination of many variables.\n",
    "\n",
    "This is where VAEs come it useful. As we saw, a VAE trained on dogs will have learned a latent, non-explicit representation of the structural features of a dog. What will happen if we pass it an instance of a sheep? It will try to reconstruct the sheep, but since the structure of a sheep is different to that of a dog, most likely the reconstruction will not be very good. As a result, the reconstruction loss will probably be quite poor on this particular sample, much worse than on dog instances -- at least if our VAE has benn properly trained. By detecting data samples that cause a large reconstruction loss, we can therefore hope to identify anomalies.\n",
    "\n",
    "The process is as follows:  \n",
    "\n",
    "- Gather and preprocess data, including train/test split,\n",
    "- Build a VAE and train it on the training set,\n",
    "- Pass test samples to the VAE and record the reconstruction loss for each,\n",
    "- Identify test samples with a reconstruction loss higher than some criterion and flag them as anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Scope of this project\n",
    "In this notebook, we will use one of the public datasets available on Kaggle: https://www.kaggle.com/boltzmannbrain/nab\n",
    "It contains many one-dimensional timeseries, but to make things a bit more interesting, we will do some feature engineering and make the data multi-dimensional. This is also often useful in improving the accuracy of any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "\n",
    "Much of the pre-processing in this section has been inspired by this great [notebook](https://www.kaggle.com/victorambonati/unsupervised-anomaly-detection) by Victor Ambonati.\n",
    "\n",
    "Before we start, we need to install and import some useful libraries. For this project, I am using [Pytorch-Lightning](https://pytorch-lightning.readthedocs.io/en/latest/), a thin layer on top of Pytorch that handles a lot of the tedious tasks such as writing a training loop. The experiments are recorded using [Weights and Biases](https://app.wandb.ai/), but you can use whatever method you want, or none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning.git\n",
      "  Cloning https://github.com/PyTorchLightning/pytorch-lightning.git to c:\\users\\niying~1\\appdata\\local\\temp\\pip-req-build-uw4fu410\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.1 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (5.3)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (4.42.1)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (0.8.4)\n",
      "Requirement already satisfied: torch>=1.3 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (1.7.1)\n",
      "Requirement already satisfied: future>=0.17.1 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.1.1rc0) (1.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.6.0.post3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (3.12.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (0.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (0.9.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.18.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.29.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (0.34.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (3.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-lightning==1.1.1rc0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (4.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in d:\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (1.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.1rc0) (2.2.0)\n",
      "Building wheels for collected packages: pytorch-lightning\n",
      "  Building wheel for pytorch-lightning (PEP 517): started\n",
      "  Building wheel for pytorch-lightning (PEP 517): finished with status 'done'\n",
      "  Created wheel for pytorch-lightning: filename=pytorch_lightning-1.1.1rc0-py3-none-any.whl size=674748 sha256=a25a3da78b2bc8ec85e30d832276e35fca9a80a0df93fc772ae5ad17fbf537e3\n",
      "  Stored in directory: C:\\Users\\NIYING~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-gd1yrcte\\wheels\\3f\\59\\d1\\6c3cb10cbcbe0b4ec861d23c98ad407afc61464ed3ed315da6\n",
      "Successfully built pytorch-lightning\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.1.0\n",
      "    Uninstalling pytorch-lightning-1.1.0:\n",
      "      Successfully uninstalled pytorch-lightning-1.1.0\n",
      "Successfully installed pytorch-lightning-1.1.1rc0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning.git 'C:\\Users\\NIYING~1\\AppData\\Local\\Temp\\pip-req-build-uw4fu410'\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/PyTorchLightning/pytorch-lightning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Requirement already up-to-date: pytorch-lightning in d:\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.3 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.6 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.41.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=5.1 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.17.1 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.8.0 in d:\\anaconda3\\lib\\site-packages (from pytorch-lightning) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.18.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.6.0.post3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in d:\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-lightning) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in d:\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in d:\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in d:\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib==3.1.3  # had issues with package incompatibilies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl,pl0\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the available datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\archive.zip\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\README.md\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialNoAnomaly\\artificialNoAnomaly\\art_daily_no_noise.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialNoAnomaly\\artificialNoAnomaly\\art_daily_perfect_square_wave.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialNoAnomaly\\artificialNoAnomaly\\art_daily_small_noise.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialNoAnomaly\\artificialNoAnomaly\\art_flatline.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialNoAnomaly\\artificialNoAnomaly\\art_noisy.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_daily_flatmiddle.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_daily_jumpsdown.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_daily_jumpsup.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_daily_nojump.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_increase_spike_density.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\artificialWithAnomaly\\artificialWithAnomaly\\art_load_balancer_spikes.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-2_cpc_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-2_cpm_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-3_cpc_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-3_cpm_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-4_cpc_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAdExchange\\realAdExchange\\exchange-4_cpm_results.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_24ae8d.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_53ea38.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_5f5533.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_77c1ca.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_825cc2.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_ac20cd.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_c6585a.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_cpu_utilization_fe7f93.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_disk_write_bytes_1ef3de.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_disk_write_bytes_c0d644.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_network_in_257a54.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\ec2_network_in_5abac7.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\elb_request_count_8c0756.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\grok_asg_anomaly.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\iio_us-east-1_i-a2eb1cd9_NetworkIn.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\rds_cpu_utilization_cc0c53.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realAWSCloudwatch\\realAWSCloudwatch\\rds_cpu_utilization_e47b3b.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\ambient_temperature_system_failure.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\cpu_utilization_asg_misconfiguration.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\ec2_request_latency_system_failure.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\machine_temperature_system_failure.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\nyc_taxi.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\rogue_agent_key_hold.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realKnownCause\\realKnownCause\\rogue_agent_key_updown.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\.DS_Store\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\occupancy_6005.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\occupancy_t4013.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\speed_6005.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\speed_7578.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\speed_t4013.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\TravelTime_387.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\realTraffic\\TravelTime_451.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\__MACOSX\\realTraffic\\._.DS_Store\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\__MACOSX\\realTraffic\\._occupancy_6005.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTraffic\\__MACOSX\\realTraffic\\._speed_6005.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_AAPL.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_AMZN.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_CRM.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_CVS.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_FB.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_GOOG.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_IBM.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_KO.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_PFE.csv\n",
      "D:/Python_Program/vae_anomaly_detection-main/kaggle/input\\nab\\realTweets\\realTweets\\Twitter_volume_UPS.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('D:/Python_Program/vae_anomaly_detection-main/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick `machine_temperature_system_failure.csv`, but the pipeline below can apply to others too, with some minor adaptation. This data comes from a temperature sensor from an internal component of a large industrial machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = Path('D:/Python_Program/vae_anomaly_detection-main/kaggle/input/nab/realKnownCause/realKnownCause/machine_temperature_system_failure.csv')\n",
    "datasets_root = Path('D:/Python_Program/vae_anomaly_detection-main/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path0 = Path('C:/Users/Ni Ying/Desktop/data/imagexlsx.xlsx')\n",
    "datasets_root0 = Path('C:/Users/Ni Ying/Desktop/data/working')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is monodimensional: It only has one \"predictor\" (`timestamp`) and the outcome (`value`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      value\n",
       "0  2013-12-02 21:15:00  73.967322\n",
       "1  2013-12-02 21:20:00  74.935882\n",
       "2  2013-12-02 21:25:00  76.124162\n",
       "3  2013-12-02 21:30:00  78.140707\n",
       "4  2013-12-02 21:35:00  79.329836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dt = pd.read_csv(datafile_path)\n",
    "raw_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>ifpic</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>asm</th>\n",
       "      <th>con</th>\n",
       "      <th>eng</th>\n",
       "      <th>idm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>166.841925</td>\n",
       "      <td>63.446047</td>\n",
       "      <td>-62.451236</td>\n",
       "      <td>158.253300</td>\n",
       "      <td>63.790080</td>\n",
       "      <td>-66.556483</td>\n",
       "      <td>156.180375</td>\n",
       "      <td>63.584990</td>\n",
       "      <td>-65.435522</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>2.5806</td>\n",
       "      <td>2.895655</td>\n",
       "      <td>0.843625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>111.179400</td>\n",
       "      <td>62.839314</td>\n",
       "      <td>-49.312123</td>\n",
       "      <td>155.679775</td>\n",
       "      <td>55.865453</td>\n",
       "      <td>-58.168950</td>\n",
       "      <td>187.076875</td>\n",
       "      <td>57.550191</td>\n",
       "      <td>-67.406039</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>4.2790</td>\n",
       "      <td>3.882789</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid type  ifpic          r1         r2         r3          g1         g2  \\\n",
       "0    1  pri      1  166.841925  63.446047 -62.451236  158.253300  63.790080   \n",
       "1   12  pri      1  111.179400  62.839314 -49.312123  155.679775  55.865453   \n",
       "2   18  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "3   22  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "4   35  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "\n",
       "          g3          b1         b2         b3       asm     con       eng  \\\n",
       "0 -66.556483  156.180375  63.584990 -65.435522  0.179038  2.5806  2.895655   \n",
       "1 -58.168950  187.076875  57.550191 -67.406039  0.049059  4.2790  3.882789   \n",
       "2   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "3   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "4   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "\n",
       "        idm  \n",
       "0  0.843625  \n",
       "1  0.663226  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dt0 = pd.read_excel(datafile_path0)\n",
    "raw_dt0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.926498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.746912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.084721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>83.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89.408246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.016252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108.510543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value\n",
       "count  22695.000000\n",
       "mean      85.926498\n",
       "std       13.746912\n",
       "min        2.084721\n",
       "25%       83.080078\n",
       "50%       89.408246\n",
       "75%       94.016252\n",
       "max      108.510543"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c44b3767c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = raw_dt.copy()\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.plot(x='timestamp', y='value', figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already intuitively see a few of unusual values. We will see if our model will be able to pick them up... For reference, the paper that introduced this dataset can be found [here](https://reader.elsevier.com/reader/sd/pii/S0925231217309864?token=C53EC725CFFDDB81C89A60CA5CA9B4DDD0E1DBFC0F8975119E6CB3555C8B2D6AC0418BF5AE7AE721DA3BB77DDD638190) \\[1\\] and its figure 1 shows this timeseries with hand-labeled anomalies. The first anomaly, around Dec 16th, is a planned shutdown. The third anomaly, around Feb 8th, is a catastrophic failure. Around Jan 30th, a harder-to-detect anomaly indicated the onset of the problem that led to anomaly 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2013-12-02 21:15:00'), Timestamp('2014-02-19 15:25:00'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['timestamp'].min(), data['timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have much information about what kind of machine or industry we are dealing with, which is a bit of an issue when trying to use this data, especially when it comes to feature engineering. We will therefore have to make assumptions. \n",
    "\n",
    "The timestamps cover the Christmas and New Year holidays. Since we are dealing with an industrial machine, it stands to reason that its workload might be affected by holidays, and maybe even by the proximity (in time) of a holiday. In the absence of additional information, we are going to assume that the applicable holidays are those typical in Europe and the Americas, i.e. Christmas and New Year's Day. By the same reasoning, we might need to know the day of the week (possibly lower workload on weekends?) or the hour of the day. Again, we will assume that weekends are Satuday and Sunday. \n",
    "\n",
    "We can easily extract all this information from the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day'] = data['timestamp'].dt.day\n",
    "data['month'] = data['timestamp'].dt.month\n",
    "data['hour_min'] = data['timestamp'].dt.hour + data['timestamp'].dt.minute / 60\n",
    "\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['holiday'] = 0\n",
    "data.loc[(data['day'] == 25) & (data['month'] == 12),'holiday'] = 1  # Christmas\n",
    "data.loc[(data['day'] == 1) & (data['month'] == 1),'holiday'] = 1  # New Year's Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  day  month   hour_min  day_of_week  holiday\n",
       "0 2013-12-02 21:15:00  73.967322    2     12  21.250000            0        0\n",
       "1 2013-12-02 21:20:00  74.935882    2     12  21.333333            0        0\n",
       "2 2013-12-02 21:25:00  76.124162    2     12  21.416667            0        0\n",
       "3 2013-12-02 21:30:00  78.140707    2     12  21.500000            0        0\n",
       "4 2013-12-02 21:35:00  79.329836    2     12  21.583333            0        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2013, 12, 25), datetime.date(2014, 1, 1)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays = data.loc[data['holiday'] == 1, 'timestamp'].dt.date.unique()\n",
    "holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add two temporary columns to compute the distance in days to or from each holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, hd in enumerate(holidays):\n",
    "    data['hol_' + str(i)] = data['timestamp'].dt.date - hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hol_0</th>\n",
       "      <th>hol_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  day  month   hour_min  day_of_week  holiday  \\\n",
       "0 2013-12-02 21:15:00  73.967322    2     12  21.250000            0        0   \n",
       "1 2013-12-02 21:20:00  74.935882    2     12  21.333333            0        0   \n",
       "2 2013-12-02 21:25:00  76.124162    2     12  21.416667            0        0   \n",
       "3 2013-12-02 21:30:00  78.140707    2     12  21.500000            0        0   \n",
       "4 2013-12-02 21:35:00  79.329836    2     12  21.583333            0        0   \n",
       "\n",
       "     hol_0    hol_1  \n",
       "0 -23 days -30 days  \n",
       "1 -23 days -30 days  \n",
       "2 -23 days -30 days  \n",
       "3 -23 days -30 days  \n",
       "4 -23 days -30 days  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested by the proximity to or from any holiday, so we want only the shortest gap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    if np.abs(data.loc[data.index[i], 'hol_0']) <= np.abs(data.loc[data.index[i], 'hol_1']):\n",
    "        data.loc[data.index[i], 'gap_holiday'] = data.loc[data.index[i], 'hol_0']\n",
    "    else:\n",
    "        data.loc[data.index[i], 'gap_holiday'] = data.loc[data.index[i], 'hol_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hol_0</th>\n",
       "      <th>hol_1</th>\n",
       "      <th>gap_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  day  month   hour_min  day_of_week  holiday  \\\n",
       "0 2013-12-02 21:15:00  73.967322    2     12  21.250000            0        0   \n",
       "1 2013-12-02 21:20:00  74.935882    2     12  21.333333            0        0   \n",
       "2 2013-12-02 21:25:00  76.124162    2     12  21.416667            0        0   \n",
       "3 2013-12-02 21:30:00  78.140707    2     12  21.500000            0        0   \n",
       "4 2013-12-02 21:35:00  79.329836    2     12  21.583333            0        0   \n",
       "\n",
       "     hol_0    hol_1 gap_holiday  \n",
       "0 -23 days -30 days    -23 days  \n",
       "1 -23 days -30 days    -23 days  \n",
       "2 -23 days -30 days    -23 days  \n",
       "3 -23 days -30 days    -23 days  \n",
       "4 -23 days -30 days    -23 days  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gap_holiday'] = data['gap_holiday'].astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hol_0</th>\n",
       "      <th>hol_1</th>\n",
       "      <th>gap_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23 days</td>\n",
       "      <td>-30 days</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  day  month   hour_min  day_of_week  holiday  \\\n",
       "0 2013-12-02 21:15:00  73.967322    2     12  21.250000            0        0   \n",
       "1 2013-12-02 21:20:00  74.935882    2     12  21.333333            0        0   \n",
       "2 2013-12-02 21:25:00  76.124162    2     12  21.416667            0        0   \n",
       "3 2013-12-02 21:30:00  78.140707    2     12  21.500000            0        0   \n",
       "4 2013-12-02 21:35:00  79.329836    2     12  21.583333            0        0   \n",
       "\n",
       "     hol_0    hol_1  gap_holiday  \n",
       "0 -23 days -30 days        -23.0  \n",
       "1 -23 days -30 days        -23.0  \n",
       "2 -23 days -30 days        -23.0  \n",
       "3 -23 days -30 days        -23.0  \n",
       "4 -23 days -30 days        -23.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer need the temporary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['hol_0', 'hol_1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>gap_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  day  month   hour_min  day_of_week  holiday  \\\n",
       "0 2013-12-02 21:15:00  73.967322    2     12  21.250000            0        0   \n",
       "1 2013-12-02 21:20:00  74.935882    2     12  21.333333            0        0   \n",
       "2 2013-12-02 21:25:00  76.124162    2     12  21.416667            0        0   \n",
       "3 2013-12-02 21:30:00  78.140707    2     12  21.500000            0        0   \n",
       "4 2013-12-02 21:35:00  79.329836    2     12  21.583333            0        0   \n",
       "\n",
       "   gap_holiday  \n",
       "0        -23.0  \n",
       "1        -23.0  \n",
       "2        -23.0  \n",
       "3        -23.0  \n",
       "4        -23.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert the timestamp into something easier to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>gap_holiday</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.967322</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.935882</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.124162</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140707</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22690</th>\n",
       "      <td>98.185415</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22691</th>\n",
       "      <td>97.804168</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22692</th>\n",
       "      <td>97.135468</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22693</th>\n",
       "      <td>98.056852</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694</th>\n",
       "      <td>96.903861</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22695 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  day  month   hour_min  day_of_week  holiday  gap_holiday  \\\n",
       "0      73.967322    2     12  21.250000            0        0        -23.0   \n",
       "1      74.935882    2     12  21.333333            0        0        -23.0   \n",
       "2      76.124162    2     12  21.416667            0        0        -23.0   \n",
       "3      78.140707    2     12  21.500000            0        0        -23.0   \n",
       "4      79.329836    2     12  21.583333            0        0        -23.0   \n",
       "...          ...  ...    ...        ...          ...      ...          ...   \n",
       "22690  98.185415   19      2  15.083333            2        0         49.0   \n",
       "22691  97.804168   19      2  15.166667            2        0         49.0   \n",
       "22692  97.135468   19      2  15.250000            2        0         49.0   \n",
       "22693  98.056852   19      2  15.333333            2        0         49.0   \n",
       "22694  96.903861   19      2  15.416667            2        0         49.0   \n",
       "\n",
       "              t  \n",
       "0      13860189  \n",
       "1      13860192  \n",
       "2      13860195  \n",
       "3      13860198  \n",
       "4      13860201  \n",
       "...         ...  \n",
       "22690  13928223  \n",
       "22691  13928226  \n",
       "22692  13928229  \n",
       "22693  13928232  \n",
       "22694  13928235  \n",
       "\n",
       "[22695 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['t'] = (data['timestamp'].astype(np.int64)/1e11).astype(np.int64)\n",
    "data.drop('timestamp', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>ifpic</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>asm</th>\n",
       "      <th>con</th>\n",
       "      <th>eng</th>\n",
       "      <th>idm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>166.841925</td>\n",
       "      <td>63.446047</td>\n",
       "      <td>-62.451236</td>\n",
       "      <td>158.253300</td>\n",
       "      <td>63.790080</td>\n",
       "      <td>-66.556483</td>\n",
       "      <td>156.180375</td>\n",
       "      <td>63.584990</td>\n",
       "      <td>-65.435522</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>2.5806</td>\n",
       "      <td>2.895655</td>\n",
       "      <td>0.843625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>111.179400</td>\n",
       "      <td>62.839314</td>\n",
       "      <td>-49.312123</td>\n",
       "      <td>155.679775</td>\n",
       "      <td>55.865453</td>\n",
       "      <td>-58.168950</td>\n",
       "      <td>187.076875</td>\n",
       "      <td>57.550191</td>\n",
       "      <td>-67.406039</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>4.2790</td>\n",
       "      <td>3.882789</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid type  ifpic          r1         r2         r3          g1         g2  \\\n",
       "0    1  pri      1  166.841925  63.446047 -62.451236  158.253300  63.790080   \n",
       "1   12  pri      1  111.179400  62.839314 -49.312123  155.679775  55.865453   \n",
       "2   18  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "3   22  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "4   35  pri      0    0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "\n",
       "          g3          b1         b2         b3       asm     con       eng  \\\n",
       "0 -66.556483  156.180375  63.584990 -65.435522  0.179038  2.5806  2.895655   \n",
       "1 -58.168950  187.076875  57.550191 -67.406039  0.049059  4.2790  3.882789   \n",
       "2   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "3   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "4   0.000000    0.000000   0.000000   0.000000  0.000000  0.0000  0.000000   \n",
       "\n",
       "        idm  \n",
       "0  0.843625  \n",
       "1  0.663226  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0=raw_dt0\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = ['value', 'hour_min', 'gap_holiday', 't']\n",
    "cat_vars = ['day', 'month', 'day_of_week', 'holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars0 = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "cat_vars0 = ['type','ifpic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply a Label Encoder to encode the categorical data from 0 to n, with n being the number of classes for the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>gap_holiday</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.967322</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.935882</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.124162</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140707</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.329836</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22690</th>\n",
       "      <td>98.185415</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22691</th>\n",
       "      <td>97.804168</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22692</th>\n",
       "      <td>97.135468</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22693</th>\n",
       "      <td>98.056852</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694</th>\n",
       "      <td>96.903861</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22695 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  day  month   hour_min  day_of_week  holiday  gap_holiday  \\\n",
       "0      73.967322    1      2  21.250000            0        0        -23.0   \n",
       "1      74.935882    1      2  21.333333            0        0        -23.0   \n",
       "2      76.124162    1      2  21.416667            0        0        -23.0   \n",
       "3      78.140707    1      2  21.500000            0        0        -23.0   \n",
       "4      79.329836    1      2  21.583333            0        0        -23.0   \n",
       "...          ...  ...    ...        ...          ...      ...          ...   \n",
       "22690  98.185415   18      1  15.083333            2        0         49.0   \n",
       "22691  97.804168   18      1  15.166667            2        0         49.0   \n",
       "22692  97.135468   18      1  15.250000            2        0         49.0   \n",
       "22693  98.056852   18      1  15.333333            2        0         49.0   \n",
       "22694  96.903861   18      1  15.416667            2        0         49.0   \n",
       "\n",
       "              t  \n",
       "0      13860189  \n",
       "1      13860192  \n",
       "2      13860195  \n",
       "3      13860198  \n",
       "4      13860201  \n",
       "...         ...  \n",
       "22690  13928223  \n",
       "22691  13928226  \n",
       "22692  13928229  \n",
       "22693  13928232  \n",
       "22694  13928235  \n",
       "\n",
       "[22695 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = [LabelEncoder() for _ in cat_vars] \n",
    "for col, enc in zip(cat_vars, label_encoders):\n",
    "    data[col] = enc.fit_transform(data[col])\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>ifpic</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>asm</th>\n",
       "      <th>con</th>\n",
       "      <th>eng</th>\n",
       "      <th>idm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>166.841925</td>\n",
       "      <td>63.446047</td>\n",
       "      <td>-62.451236</td>\n",
       "      <td>158.253300</td>\n",
       "      <td>63.790080</td>\n",
       "      <td>-66.556483</td>\n",
       "      <td>156.180375</td>\n",
       "      <td>63.584990</td>\n",
       "      <td>-65.435522</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>2.5806</td>\n",
       "      <td>2.895655</td>\n",
       "      <td>0.843625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>111.179400</td>\n",
       "      <td>62.839314</td>\n",
       "      <td>-49.312123</td>\n",
       "      <td>155.679775</td>\n",
       "      <td>55.865453</td>\n",
       "      <td>-58.168950</td>\n",
       "      <td>187.076875</td>\n",
       "      <td>57.550191</td>\n",
       "      <td>-67.406039</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>4.2790</td>\n",
       "      <td>3.882789</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63658</th>\n",
       "      <td>1817710</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>88.309425</td>\n",
       "      <td>59.678349</td>\n",
       "      <td>53.144456</td>\n",
       "      <td>72.491300</td>\n",
       "      <td>46.649307</td>\n",
       "      <td>43.335417</td>\n",
       "      <td>56.603550</td>\n",
       "      <td>44.023987</td>\n",
       "      <td>42.715452</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>3.480351</td>\n",
       "      <td>0.758520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63659</th>\n",
       "      <td>1817712</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63660</th>\n",
       "      <td>1817890</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>187.832400</td>\n",
       "      <td>73.076020</td>\n",
       "      <td>-76.987670</td>\n",
       "      <td>155.453025</td>\n",
       "      <td>55.151594</td>\n",
       "      <td>-33.555261</td>\n",
       "      <td>89.282200</td>\n",
       "      <td>55.796176</td>\n",
       "      <td>50.441616</td>\n",
       "      <td>0.038189</td>\n",
       "      <td>2.9433</td>\n",
       "      <td>3.854994</td>\n",
       "      <td>0.730024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63661</th>\n",
       "      <td>1823090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204.942675</td>\n",
       "      <td>41.241178</td>\n",
       "      <td>-37.723090</td>\n",
       "      <td>121.325050</td>\n",
       "      <td>43.164924</td>\n",
       "      <td>25.844677</td>\n",
       "      <td>86.205650</td>\n",
       "      <td>32.699973</td>\n",
       "      <td>-16.954191</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>1.0046</td>\n",
       "      <td>3.640017</td>\n",
       "      <td>0.741229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63662</th>\n",
       "      <td>1825048</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63663 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  type  ifpic          r1         r2         r3          g1  \\\n",
       "0            1     2      1  166.841925  63.446047 -62.451236  158.253300   \n",
       "1           12     2      1  111.179400  62.839314 -49.312123  155.679775   \n",
       "2           18     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "3           22     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "4           35     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "...        ...   ...    ...         ...        ...        ...         ...   \n",
       "63658  1817710     2      1   88.309425  59.678349  53.144456   72.491300   \n",
       "63659  1817712     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "63660  1817890     2      1  187.832400  73.076020 -76.987670  155.453025   \n",
       "63661  1823090     1      1  204.942675  41.241178 -37.723090  121.325050   \n",
       "63662  1825048     1      0    0.000000   0.000000   0.000000    0.000000   \n",
       "\n",
       "              g2         g3          b1         b2         b3       asm  \\\n",
       "0      63.790080 -66.556483  156.180375  63.584990 -65.435522  0.179038   \n",
       "1      55.865453 -58.168950  187.076875  57.550191 -67.406039  0.049059   \n",
       "2       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "3       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "4       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "...          ...        ...         ...        ...        ...       ...   \n",
       "63658  46.649307  43.335417   56.603550  44.023987  42.715452  0.056898   \n",
       "63659   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "63660  55.151594 -33.555261   89.282200  55.796176  50.441616  0.038189   \n",
       "63661  43.164924  25.844677   86.205650  32.699973 -16.954191  0.039200   \n",
       "63662   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "\n",
       "          con       eng       idm  \n",
       "0      2.5806  2.895655  0.843625  \n",
       "1      4.2790  3.882789  0.663226  \n",
       "2      0.0000  0.000000  0.000000  \n",
       "3      0.0000  0.000000  0.000000  \n",
       "4      0.0000  0.000000  0.000000  \n",
       "...       ...       ...       ...  \n",
       "63658  0.9922  3.480351  0.758520  \n",
       "63659  0.0000  0.000000  0.000000  \n",
       "63660  2.9433  3.854994  0.730024  \n",
       "63661  1.0046  3.640017  0.741229  \n",
       "63662  0.0000  0.000000  0.000000  \n",
       "\n",
       "[63663 rows x 16 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders0 = [LabelEncoder() for _0 in cat_vars0] \n",
    "for col, enc in zip(cat_vars0, label_encoders0):\n",
    "    data0[col] = enc.fit_transform(data0[col])\n",
    "    \n",
    "data0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some of our data are continuous (or 'close to' continuous): `value`, `hour_min`, `gap_holiday` (even though this one only has a resolution of 1 day), `t`. Other variables are categorical: `day`, `month`, `day_week`, `holiday`. In a neural network model, these two types of data need to be handled differently, as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to split our data into a train set and a test set. Let's set 30% of the data aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15886, 6809)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_idx = np.random.choice(np.arange(data.shape[0]), size=round(data.shape[0] * (1 - test_ratio)), replace=False)\n",
    "tst_idx = list(set(range(data.shape[0])).difference(set(tr_idx)))\n",
    "len(tr_idx), len(tst_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44564, 19099)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_idx0 = np.random.choice(np.arange(data0.shape[0]), size=round(data0.shape[0] * (1 - test_ratio)), replace=False)\n",
    "tst_idx0 = list(set(range(data0.shape[0])).difference(set(tr_idx0)))\n",
    "len(tr_idx0), len(tst_idx0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = data.iloc[tr_idx]\n",
    "tst_data = data.iloc[tst_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data0 = data0.iloc[tr_idx0]\n",
    "tst_data0 = data0.iloc[tst_idx0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using a neural network model, the continuous variables need to be normalised. This is important because the weights of a neural network are initialised at random from a common distribution, so all tend to have similar scales initially. Variables whose values spread are across different orders of magnitude would therefore cause serious difficulties when it comes to learning the optimal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(tr_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler0 = preprocessing.StandardScaler().fit(tr_data0[cont_vars0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled = tr_data.copy()\n",
    "tr_data_scaled[cont_vars] = scaler.transform(tr_data[cont_vars])\n",
    "tst_data_scaled = tst_data.copy()\n",
    "tst_data_scaled[cont_vars] = scaler.transform(tst_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled0 = tr_data0.copy()\n",
    "tr_data_scaled0[cont_vars0] = scaler0.transform(tr_data0[cont_vars0])\n",
    "tst_data_scaled0 = tst_data0.copy()\n",
    "tst_data_scaled0[cont_vars0] = scaler0.transform(tst_data0[cont_vars0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the test data is normalised using parameters observed on the train set. Otherwise, we would be cheating!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            value  day  month   hour_min  day_of_week  holiday  gap_holiday  \\\n",
       " 2844    95.534846   11      2  18.250000            3        0        -13.0   \n",
       " 4370   101.627039   17      2   1.416667            2        0         -7.0   \n",
       " 14603   67.240949   21      0  13.166667            2        0         21.0   \n",
       " 17380   91.884523    0      1   4.583333            5        0         31.0   \n",
       " 14812   89.231189   22      0   6.583333            3        0         22.0   \n",
       " ...           ...  ...    ...        ...          ...      ...          ...   \n",
       " 14703   88.309045   21      0  21.500000            2        0         21.0   \n",
       " 11241   95.605787    9      0  21.000000            4        0          9.0   \n",
       " 19325   47.473921    6      1  22.666667            4        0         37.0   \n",
       " 8981    87.225003    2      0   1.666667            4        0          2.0   \n",
       " 5615    88.512443   21      2   9.166667            6        0         -3.0   \n",
       " \n",
       "               t  \n",
       " 2844   13868721  \n",
       " 4370   13873299  \n",
       " 14603  13903962  \n",
       " 17380  13912293  \n",
       " 14812  13904589  \n",
       " ...         ...  \n",
       " 14703  13904262  \n",
       " 11241  13893876  \n",
       " 19325  13918128  \n",
       " 8981   13887132  \n",
       " 5615   13877034  \n",
       " \n",
       " [15886 rows x 8 columns],\n",
       "           value  day  month  hour_min  day_of_week  holiday  gap_holiday  \\\n",
       " 2844   0.700781   11      2  0.913782            3        0    -1.239988   \n",
       " 4370   1.142026   17      2 -1.516833            2        0    -0.942251   \n",
       " 14603 -1.348485   21      0  0.179785            2        0     0.447186   \n",
       " 17380  0.436396    0      1 -1.059589            5        0     0.943413   \n",
       " 14812  0.244221   22      0 -0.770803            3        0     0.496809   \n",
       " ...         ...  ...    ...       ...          ...      ...          ...   \n",
       " 14703  0.177432   21      0  1.383060            2        0     0.447186   \n",
       " 11241  0.705919    9      0  1.310863            4        0    -0.148287   \n",
       " 19325 -2.780169    6      1  1.551518            4        0     1.241150   \n",
       " 8981   0.098917    2      0 -1.480735            4        0    -0.495647   \n",
       " 5615   0.192163   21      2 -0.397788            6        0    -0.743760   \n",
       " \n",
       "               t  \n",
       " 2844  -1.292080  \n",
       " 4370  -1.059213  \n",
       " 14603  0.500504  \n",
       " 17380  0.924273  \n",
       " 14812  0.532398  \n",
       " ...         ...  \n",
       " 14703  0.515764  \n",
       " 11241 -0.012535  \n",
       " 19325  1.221078  \n",
       " 8981  -0.355578  \n",
       " 5615  -0.869227  \n",
       " \n",
       " [15886 rows x 8 columns])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_data_scaled = pd.DataFrame(tr_data_scaled, columns=tr_data.columns)\n",
    "# tst_data_scaled = pd.DataFrame(tst_data_scaled, columns=tst_data.columns)\n",
    "\n",
    "tr_data, tr_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           uid  type  ifpic          r1         r2         r3        g1  \\\n",
       " 15637   567658     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 47422  1362805     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 13766   257571     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 48066  1379735     2      1  167.924325  77.400728 -74.485576  139.5890   \n",
       " 14524   289017     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " ...        ...   ...    ...         ...        ...        ...       ...   \n",
       " 58734  1628085     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 28339  1002153     2      1  104.293225  50.831825 -26.277413  104.2601   \n",
       " 30908  1051474     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 62097  1738727     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " 52584  1489267     2      0    0.000000   0.000000   0.000000    0.0000   \n",
       " \n",
       "               g2         g3         b1         b2         b3       asm  \\\n",
       " 15637   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 47422   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 13766   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 48066  74.730134 -56.589506  54.953425  55.172592  58.834907  0.027124   \n",
       " 14524   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " ...          ...        ...        ...        ...        ...       ...   \n",
       " 58734   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 28339  51.616274 -23.015292  96.630050  51.120180  19.609543  0.036681   \n",
       " 30908   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 62097   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " 52584   0.000000   0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       " \n",
       "           con       eng       idm  \n",
       " 15637  0.0000  0.000000  0.000000  \n",
       " 47422  0.0000  0.000000  0.000000  \n",
       " 13766  0.0000  0.000000  0.000000  \n",
       " 48066  2.9303  4.091153  0.678122  \n",
       " 14524  0.0000  0.000000  0.000000  \n",
       " ...       ...       ...       ...  \n",
       " 58734  0.0000  0.000000  0.000000  \n",
       " 28339  1.9933  3.879082  0.695916  \n",
       " 30908  0.0000  0.000000  0.000000  \n",
       " 62097  0.0000  0.000000  0.000000  \n",
       " 52584  0.0000  0.000000  0.000000  \n",
       " \n",
       " [44564 rows x 16 columns],\n",
       "            uid  type  ifpic        r1        r2        r3        g1        g2  \\\n",
       " 15637   567658     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 47422  1362805     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 13766   257571     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 48066  1379735     2      1  1.462956  1.852207 -2.104211  1.211036  1.752937   \n",
       " 14524   289017     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " ...        ...   ...    ...       ...       ...       ...       ...       ...   \n",
       " 58734  1628085     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 28339  1002153     2      1  0.661473  0.993983 -0.616578  0.740026  1.007870   \n",
       " 30908  1051474     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 62097  1738727     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " 52584  1489267     2      0 -0.652181 -0.647978  0.194305 -0.649984 -0.655964   \n",
       " \n",
       "              g3        b1        b2        b3       asm       con       eng  \\\n",
       " 15637  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 47422  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 13766  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 48066 -1.611580  0.130014  1.091803  1.863654 -0.213829  0.965329  1.950691   \n",
       " 14524  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 58734  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 28339 -0.563769  0.708403  0.964110  0.675851 -0.136627  0.503479  1.814906   \n",
       " 30908  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 62097  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " 52584  0.154511 -0.632632 -0.646710  0.082044 -0.432958 -0.479024 -0.668800   \n",
       " \n",
       "             idm  \n",
       " 15637 -0.700623  \n",
       " 47422 -0.700623  \n",
       " 13766 -0.700623  \n",
       " 48066  1.154266  \n",
       " 14524 -0.700623  \n",
       " ...         ...  \n",
       " 58734 -0.700623  \n",
       " 28339  1.202937  \n",
       " 30908 -0.700623  \n",
       " 62097 -0.700623  \n",
       " 52584 -0.700623  \n",
       " \n",
       " [44564 rows x 16 columns])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data0, tr_data_scaled0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the continuous variables are now standardised, while the categorical variables are unchanged. We can now save our data as CSV files and we are ready for the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled.to_csv(datasets_root/'train.csv', index=False)\n",
    "tst_data_scaled.to_csv(datasets_root/'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled0.to_csv(datasets_root0/'img_train.csv', index=False)\n",
    "tst_data_scaled0.to_csv(datasets_root0/'img_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Python_Program/vae_anomaly_detection-main/kaggle/working')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VAE Model\n",
    "We first define a `Dataset` class that takes data from either the train set or the test set. It is also able to filter out some of the columns.\n",
    "\n",
    "**Note**: For VAE training, we want to use the column `value` as a feature rather than a label, because we are doing unsupervised learning. In that case, we set the argument `lbl_as_feat` to True. If we were training a supervised model, then we would be able to use the same `Dataset` class but we would need to set `lbl_as_feat` to False, and the dataset would return `value` as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset(Dataset):\n",
    "    def __init__(self, split, cont_vars=None, cat_vars=None, lbl_as_feat=True):\n",
    "        \"\"\"\n",
    "        split: 'train' if we want to get data from the training examples, 'test' for\n",
    "        test examples, or 'both' to merge the training and test sets and return samples\n",
    "        from either.\n",
    "        cont_vars: List of continuous variables to return as features. If None, returns\n",
    "        all continuous variables available.\n",
    "        cat_vars: Same as above, but for categorical variables.\n",
    "        lbl_as_feat: Set to True when training a VAE -- the labels (temperature values)\n",
    "        will be included as another dimension of the data. Set to False when training\n",
    "        a model to predict temperatures.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert split in ['train', 'test', 'both']\n",
    "        self.lbl_as_feat = lbl_as_feat\n",
    "        if split == 'train':\n",
    "            self.df = pd.read_csv(datasets_root/'train.csv')\n",
    "        elif split == 'test':\n",
    "            self.df = pd.read_csv(datasets_root/'test.csv')\n",
    "        else:\n",
    "            df1 = pd.read_csv(datasets_root/'train.csv')\n",
    "            df2 = pd.read_csv(datasets_root/'test.csv')\n",
    "            self.df = pd.concat((df1, df2), ignore_index=True)\n",
    "        \n",
    "        # Select continuous variables to use\n",
    "        if cont_vars:\n",
    "            self.cont_vars = cont_vars\n",
    "            # If we want to use 'value' as a feature, ensure it is returned\n",
    "            if self.lbl_as_feat:\n",
    "                try:\n",
    "                    assert 'value' in self.cont_vars\n",
    "                except AssertionError:\n",
    "                    self.cont_vars.insert(0, 'value')\n",
    "            # If not, ensure it not returned as a feature\n",
    "            else:\n",
    "                try:\n",
    "                    assert 'value' not in self.cont_vars\n",
    "                except AssertionError:\n",
    "                    self.cont_vars.remove('value')\n",
    "                    \n",
    "        else:  # if no list provided, use all available\n",
    "            self.cont_vars = ['value', 'hour_min', 'gap_holiday', 't']\n",
    "        \n",
    "        # Select categorical variables to use\n",
    "        if cat_vars:\n",
    "            self.cat_vars = cat_vars\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cat_vars = ['day', 'month', 'day_of_week', 'holiday']\n",
    "        \n",
    "        # Finally, make two Numpy arrays for continuous and categorical\n",
    "        # variables, respectively:\n",
    "        if self.lbl_as_feat:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "            self.lbl = self.df['value'].copy().to_numpy(dtype=np.float32)\n",
    "        self.cat = self.df[self.cat_vars].copy().to_numpy(dtype=np.int64)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if self.lbl_as_feat:  # for VAE training\n",
    "            return torch.tensor(self.cont[idx]), torch.tensor(self.cat[idx])\n",
    "        else:  # for supervised prediction\n",
    "            return torch.tensor(self.cont[idx]), torch.tensor(self.cat[idx]), torch.tensor(self.lbl[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset0(Dataset):\n",
    "    def __init__(self, split, cont_vars0=None, cat_vars0=None, lbl_as_feat=True):\n",
    "        \"\"\"\n",
    "        split: 'train' if we want to get data from the training examples, 'test' for\n",
    "        test examples, or 'both' to merge the training and test sets and return samples\n",
    "        from either.\n",
    "        cont_vars: List of continuous variables to return as features. If None, returns\n",
    "        all continuous variables available.\n",
    "        cat_vars: Same as above, but for categorical variables.\n",
    "        lbl_as_feat: Set to True when training a VAE -- the labels (temperature values)\n",
    "        will be included as another dimension of the data. Set to False when training\n",
    "        a model to predict temperatures.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert split in ['train', 'test', 'both']\n",
    "        self.lbl_as_feat = lbl_as_feat\n",
    "        if split == 'train':\n",
    "            self.df = pd.read_csv(datasets_root0/'img_train.csv')\n",
    "        elif split == 'test':\n",
    "            self.df = pd.read_csv(datasets_root0/'img_test.csv')\n",
    "        else:\n",
    "            df1 = pd.read_csv(datasets_root0/'img_train.csv')\n",
    "            df2 = pd.read_csv(datasets_root0/'img_test.csv')\n",
    "            self.df = pd.concat((df1, df2), ignore_index=True)\n",
    "        \n",
    "        if cat_vars:\n",
    "            self.cont_vars0 = cont_vars0\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cont_vars0 = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "\n",
    "        # Select categorical variables to use\n",
    "        if cat_vars:\n",
    "            self.cat_vars0 = cat_vars0\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cat_vars0 = ['ifpic']\n",
    "        \n",
    "        # Finally, make two Numpy arrays for continuous and categorical\n",
    "        # variables, respectively:\n",
    "        if self.lbl_as_feat:\n",
    "            self.cont0 = self.df[self.cont_vars0].copy().to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            self.cont0 = self.df[self.cont_vars0].copy().to_numpy(dtype=np.float32)\n",
    "            self.lbl0 = self.df['type'].copy().to_numpy(dtype=np.float32)\n",
    "        self.cat0 = self.df[self.cat_vars0].copy().to_numpy(dtype=np.int64)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if self.lbl_as_feat:  # for VAE training\n",
    "            return torch.tensor(self.cont0[idx]), torch.tensor(self.cat0[idx])\n",
    "        else:  # for supervised prediction\n",
    "            return torch.tensor(self.cont0[idx]), torch.tensor(self.cat0[idx]), torch.tensor(self.lbl0[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to call from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22695\n",
      "(tensor([ 0.7008, -1.2921]), tensor([3, 0]))\n",
      "(tensor([ 1.1420, -1.0592]), tensor([2, 0]))\n",
      "(tensor([-1.3485,  0.5005]), tensor([2, 0]))\n",
      "(tensor([0.4364, 0.9243]), tensor([5, 0]))\n",
      "(tensor([0.2442, 0.5324]), tensor([3, 0]))\n",
      "(tensor([-0.2778, -0.5511]), tensor([6, 0]))\n",
      "(tensor([0.4789, 0.1675]), tensor([1, 0]))\n",
      "(tensor([0.2147, 0.3046]), tensor([5, 0]))\n",
      "(tensor([-2.6544, -1.1354]), tensor([0, 0]))\n",
      "(tensor([-1.9039, -0.2460]), tensor([6, 0]))\n"
     ]
    }
   ],
   "source": [
    "ds = TSDataset(split='both', cont_vars=['value', 't'], cat_vars=['day_of_week', 'holiday'], lbl_as_feat=True)\n",
    "print(len(ds))\n",
    "it = iter(ds)\n",
    "for _ in range(10):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63663\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([ 1.4630,  1.8522, -2.1042,  1.2110,  1.7529, -1.6116,  0.1300,  1.0918,\n",
      "         1.8637, -0.2138,  0.9653,  1.9507,  1.1543]), tensor([1]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n",
      "(tensor([ 0.5664,  0.5036,  0.9900,  1.1422,  0.4993,  0.7818,  1.5842,  0.4492,\n",
      "         0.6388,  0.7058, -0.1482,  0.9345,  1.6608]), tensor([1]))\n",
      "(tensor([-0.6522, -0.6480,  0.1943, -0.6500, -0.6560,  0.1545, -0.6326, -0.6467,\n",
      "         0.0820, -0.4330, -0.4790, -0.6688, -0.7006]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "ds0 = TSDataset0(split='both', cont_vars0=['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm'], cat_vars0=['ifpic'], lbl_as_feat=True)\n",
    "print(len(ds0))\n",
    "it0 = iter(ds0)\n",
    "for _0 in range(10):\n",
    "    print(next(it0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, with `lbl_as_feat==True`, we get two arrays for each sample: An array of continuous values represented by floats, and an array of categorical values represented by integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to the fun part: The model itself. First, define individual modules. The core of our neural network will be a sequence of fully connected layers, whose number and sizes are passed through the hyperparameter `layer_dims` (a list of integers). In our experiment, we used `64,128,64`, i.e. 3 layers of dimensions 64, 128 and 64. Each layer can be batch-normalised. The input into the first layer is an aggregation of the continuous variables and embedding vectors encoding the categorical variables. \n",
    "\n",
    "Embedding vectors are a notion that is heavily used in Natural Language Processing. They are learnable vectors (of dimension 8 in our experiments) that express some non-explicit features of the variables. For instance, the vector for `day_of_week` can take 7 different sets of values (one for each day), each 8-dimensional. Depending on the value of this variable for each sample, the corresponding vector is retrieved in a lookup table, passed to the network, and updated during backpropagation. The vector for `day_of_week==0` could eventually encode the fact that the machine's activity is lower on such days, for instance. The important thing is that this learning is done without our intervention, and there is no easy way to interpret the learned embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    '''\n",
    "    A single fully connected layer with optional batch normalisation and activation.\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, bn = True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, out_dim)]\n",
    "        if bn: layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    The encoder part of our VAE. Takes a data sample and returns the mean and the log-variance of the \n",
    "    latent vector's distribution.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeds = nn.ModuleList([\n",
    "            nn.Embedding(n_cats, emb_size) for (n_cats, emb_size) in hparams.embedding_sizes\n",
    "        ])\n",
    "        # The input to the first layer is the concatenation of all embedding vectors and continuous\n",
    "        # values\n",
    "        in_dim = sum(emb.embedding_dim for emb in self.embeds) + len(hparams.cont_vars)\n",
    "        layer_dims = [in_dim] + [int(s) for s in hparams.layer_sizes.split(',')]\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(layer_dims[i], layer_dims[i + 1], bn) for i in range(len(layer_dims) - 1)],\n",
    "        )\n",
    "        self.mu = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "        self.logvar = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "    \n",
    "    def forward(self, x_cont, x_cat):\n",
    "        x_embed = [e(x_cat[:, i]) for i, e in enumerate(self.embeds)]        \n",
    "        x_embed = torch.cat(x_embed, dim=1)\n",
    "        x = torch.cat((x_embed, x_cont), dim=1)\n",
    "        h = self.layers(x)\n",
    "        mu_ = self.mu(h)\n",
    "        logvar_ = self.logvar(h)\n",
    "        return mu_, logvar_, x  # we return the concatenated input vector for use in loss fn\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    The decoder part of our VAE. Takes a latent vector (sampled from the distribution learned by the \n",
    "    encoder) and converts it back to a reconstructed data sample.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "#         self.final_activ = hparams.final_activ\n",
    "        hidden_dims = [hparams.latent_dim] + [int(s) for s in reversed(hparams.layer_sizes.split(','))]\n",
    "        out_dim = sum(emb_size for _, emb_size in hparams.embedding_sizes) + len(hparams.cont_vars)\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(hidden_dims[i], hidden_dims[i + 1], bn) for i in range(len(hidden_dims) - 1)],\n",
    "        )\n",
    "        self.reconstructed = nn.Linear(hidden_dims[-1], out_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = self.layers(z)\n",
    "        recon = self.reconstructed(h)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the full VAE, defined as a LightningModule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        if isinstance(hparams, dict):\n",
    "            hparams = Namespace(**hparams)\n",
    "        self.hparams = hparams\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.stdev = hparams.stdev\n",
    "        self.kld_beta = hparams.kld_beta\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.weight_decay\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        '''\n",
    "        The reparameterisation trick allows us to backpropagate through the encoder.\n",
    "        '''\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std) * self.stdev\n",
    "            return eps * std + mu\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x_cont, x_cat = batch\n",
    "        assert x_cat.dtype == torch.int64\n",
    "        mu, logvar, x = self.encoder(x_cont, x_cat)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, mu, logvar, x\n",
    "        \n",
    "    def loss_function(self, obs, recon, mu, logvar):\n",
    "#         recon_loss = F.mse_loss(recon, obs, reduction='sum')\n",
    "        recon_loss = F.smooth_l1_loss(recon, obs, reduction='sum')\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp())\n",
    "        return recon_loss, kld\n",
    "                               \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        # The loss function compares the concatenated input vector including\n",
    "        # embeddings to the reconstructed vector\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "\n",
    "        self.log('total_tr_loss', loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('recon_loss', recon_loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('kld', kld.mean(dim=0), on_step=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, \n",
    "                                weight_decay=self.hparams.weight_decay, \n",
    "                                eps=1e-4)\n",
    "        sch = torch.optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda epoch: 0.95)\n",
    "        return opt\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TSDataset0('train', cont_vars0=self.hparams.cont_vars, \n",
    "                            cat_vars0 = self.hparams.cat_vars, lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        dataset = TSDataset0('test', cont_vars0=self.hparams.cont_vars,\n",
    "                            cat_vars0=self.hparams.cat_vars, lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that different reconstruction loss functions are possible, the most obvious being the Mean Square Error (MSE). However, it is quite sensitive to outliers. In our case, almost by definition, we expect outliers to be present so it might be useful to use a loss function that is less sensitive to them. We use the Huber loss with $\\delta=1$ (called `smooth_l1_loss` in Pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model and data hyperparameters. Note that `stdev` (the standard deviation of the normal distribution from which we sample $\\epsilon$ in the `reparameterize()` method) would typically be 1. However, several papers found improvements with smaller values, such as 1e-2. This is what we are going to use, as it gives us lower loss values.\n",
    "\n",
    "Another hyperparameter worth mentioning is `kld_beta`, the coefficient applied to the KLD loss term in the total loss computation (this hyperparameter means that our VAE is technically a $\\beta$-VAE). This helps because the reconstruction loss is typically harder to improve than the KLD loss, therefore if both were weighted equally, the model would start by optimising the KLD loss before improving the reconstruction loss substantially. By setting this coefficient to a value < 1, we try to make sure that both loss values improve at a similar rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = ['value', 'hour_min', 'gap_holiday', 't'] \n",
    "cat_features = ['day', 'month', 'day_of_week', 'holiday'] \n",
    "\n",
    "embed_cats = [len(tr_data_scaled[c].unique()) for c in cat_features]\n",
    "\n",
    "hparams = OrderedDict(\n",
    "    run='all_vars_embsz8_latsz32_bsz64_lay64-128-64_ep200v3',\n",
    "    cont_vars = cont_features,\n",
    "    cat_vars = cat_features,\n",
    "    embedding_sizes = [(embed_cats[i], 8) for i in range(len(embed_cats))],\n",
    "    latent_dim = 32,\n",
    "    layer_sizes = '64,128,64',\n",
    "    batch_norm = True,\n",
    "    stdev = 0.01,\n",
    "    kld_beta = 0.2,\n",
    "    lr = 0.01,\n",
    "    weight_decay = 1e-5,\n",
    "    batch_size = 64,\n",
    "    epochs = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features0 = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "cat_features0 = ['ifpic'] \n",
    "\n",
    "embed_cats0 = [len(tr_data_scaled0[c].unique()) for c in cat_features0]\n",
    "\n",
    "hparams0 = OrderedDict(\n",
    "    run='img_vars_embsz8_latsz32_bsz64_lay64-128-64_ep50',\n",
    "    cont_vars = cont_features0,\n",
    "    cat_vars = cat_features0,\n",
    "    embedding_sizes = [(embed_cats0[i], 14) for i in range(len(embed_cats0))],\n",
    "    latent_dim = 32,\n",
    "    layer_sizes = '64,128,64',\n",
    "    batch_norm = True,\n",
    "    stdev = 0.01,\n",
    "    kld_beta = 0.2,\n",
    "    lr = 0.01,\n",
    "    weight_decay = 1e-5,\n",
    "    batch_size = 64,\n",
    "    epochs = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('run', 'img_vars_embsz8_latsz32_bsz64_lay64-128-64_ep50'),\n",
       "             ('cont_vars',\n",
       "              ['r1',\n",
       "               'r2',\n",
       "               'r3',\n",
       "               'g1',\n",
       "               'g2',\n",
       "               'g3',\n",
       "               'b1',\n",
       "               'b2',\n",
       "               'b3',\n",
       "               'asm',\n",
       "               'con',\n",
       "               'eng',\n",
       "               'idm']),\n",
       "             ('cat_vars', ['ifpic']),\n",
       "             ('embedding_sizes', [(2, 14)]),\n",
       "             ('latent_dim', 32),\n",
       "             ('layer_sizes', '64,128,64'),\n",
       "             ('batch_norm', True),\n",
       "             ('stdev', 0.01),\n",
       "             ('kld_beta', 0.2),\n",
       "             ('lr', 0.01),\n",
       "             ('weight_decay', 1e-05),\n",
       "             ('batch_size', 64),\n",
       "             ('epochs', 50)])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "# Simulate a Namespace with the defined hyperparameters\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams0 = Namespace(**hparams0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's choose our learning rate. Instead of searching ourselves, we leverage a functionality provided by Pytorch-Lightning that automates the search for this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VAE(hparams)\n",
    "logger = WandbLogger(name=hparams.run, project='VAE_Anomaly', version=hparams.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model0 = VAE(hparams0)\n",
    "logger0 = WandbLogger(name=hparams0.run, project='VAE_Anomaly0', version=hparams0.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(2, 14)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=27, out_features=64, bias=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mu): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (logvar): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): Sequential(\n",
       "      (0): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Layer(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reconstructed): Linear(in_features=64, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 24.0 K\n",
      "1 | decoder | Decoder | 21.5 K\n",
      "------------------------------------\n",
      "45.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.5 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc89584ceb6f4fe08532a62a5c903bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.006918309709189364\n"
     ]
    }
   ],
   "source": [
    "ckpt_callback = pl.callbacks.ModelCheckpoint(filepath='./vae_weights')\n",
    "# Replace argument logger by None if you don't have a WandB account (and don't want to create one)\n",
    "trainer = pl.Trainer(gpus=None,logger=logger, max_epochs=hparams.epochs, \n",
    "                     auto_lr_find=True, benchmark=True, callbacks=[ckpt_callback],\n",
    "                     gradient_clip_val=1.\n",
    "                     )\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 23.1 K\n",
      "1 | decoder | Decoder | 21.0 K\n",
      "------------------------------------\n",
      "44.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.0 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4b3f6beb474d90b1b97f3b9d4ef5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early due to diverging loss.\n",
      "Learning rate set to 1.0964781961431852e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_callback0 = pl0.callbacks.ModelCheckpoint(filepath='C:/Users/Ni Ying/Desktop/data/vae_weights')\n",
    "# Replace argument logger by None if you don't have a WandB account (and don't want to create one)\n",
    "trainer0 = pl0.Trainer(gpus=None,logger=logger, max_epochs=hparams0.epochs, \n",
    "                     auto_lr_find=True, benchmark=True, callbacks=[ckpt_callback],\n",
    "                     gradient_clip_val=1.\n",
    "                     )\n",
    "trainer0.tune(model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ny0421 (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">all_vars_embsz8_latsz32_bsz64_lay64-128-64_ep200v3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ny0421/vae_anomaly\" target=\"_blank\">https://wandb.ai/ny0421/vae_anomaly</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ny0421/vae_anomaly/runs/all_vars_embsz8_latsz32_bsz64_lay64-128-64_ep200v3\" target=\"_blank\">https://wandb.ai/ny0421/vae_anomaly/runs/all_vars_embsz8_latsz32_bsz64_lay64-128-64_ep200v3</a><br/>\n",
       "                Run data is saved locally in <code>D:\\Python_Program\\vae_anomaly_detection-main\\wandb\\run-20201214_174546-all_vars_embsz8_latsz32_bsz64_lay64-128-64_ep200v3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 24.0 K\n",
      "1 | decoder | Decoder | 21.5 K\n",
      "------------------------------------\n",
      "45.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.5 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9068401de27f4535905b88cfed355a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 23.1 K\n",
      "1 | decoder | Decoder | 21.0 K\n",
      "------------------------------------\n",
      "44.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.0 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a99437163664e42ae6003b474ff4239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Step must only increase in log calls.  Step 142 < 34247; dropping {'total_tr_loss': 3.9657773971557617, 'recon_loss': 3.571672201156616, 'kld': 1.9705262184143066}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 192 < 34247; dropping {'total_tr_loss': 6.256096839904785, 'recon_loss': 5.861252307891846, 'kld': 1.9742237329483032}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 242 < 34247; dropping {'total_tr_loss': 3.8566410541534424, 'recon_loss': 3.4120752811431885, 'kld': 2.2228286266326904}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 292 < 34247; dropping {'total_tr_loss': 6.7722883224487305, 'recon_loss': 6.229997634887695, 'kld': 2.7114522457122803}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 342 < 34247; dropping {'total_tr_loss': 4.108344078063965, 'recon_loss': 3.650745391845703, 'kld': 2.2879929542541504}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 392 < 34247; dropping {'total_tr_loss': 6.037087917327881, 'recon_loss': 5.5202131271362305, 'kld': 2.5843746662139893}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 442 < 34247; dropping {'total_tr_loss': 4.622122287750244, 'recon_loss': 4.056758880615234, 'kld': 2.8268160820007324}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 492 < 34247; dropping {'total_tr_loss': 3.9820475578308105, 'recon_loss': 3.5414624214172363, 'kld': 2.2029261589050293}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 542 < 34247; dropping {'total_tr_loss': 5.0267462730407715, 'recon_loss': 4.561115264892578, 'kld': 2.3281545639038086}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 592 < 34247; dropping {'total_tr_loss': 3.986910343170166, 'recon_loss': 3.583820343017578, 'kld': 2.0154500007629395}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 642 < 34247; dropping {'total_tr_loss': 4.47297477722168, 'recon_loss': 4.1280670166015625, 'kld': 1.7245397567749023}.\n",
      "wandb: WARNING Step must only increase in log calls.  Step 692 < 34247; dropping {'total_tr_loss': 4.546621322631836, 'recon_loss': 4.085858345031738, 'kld': 2.3038153648376465}.\n",
      "D:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer0.fit(model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VAE:\n\tMissing key(s) in state_dict: \"encoder.embeds.1.weight\", \"encoder.embeds.2.weight\", \"encoder.embeds.3.weight\". \n\tsize mismatch for encoder.embeds.0.weight: copying a param with shape torch.Size([2, 14]) from checkpoint, the shape in current model is torch.Size([31, 8]).\n\tsize mismatch for encoder.layers.0.block.0.weight: copying a param with shape torch.Size([64, 27]) from checkpoint, the shape in current model is torch.Size([64, 36]).\n\tsize mismatch for decoder.reconstructed.weight: copying a param with shape torch.Size([27, 64]) from checkpoint, the shape in current model is torch.Size([36, 64]).\n\tsize mismatch for decoder.reconstructed.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([36]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-24edee734c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m__test_using_best_weights\u001b[1;34m(self, ckpt_path, test_dataloaders)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;31m# attach dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VAE:\n\tMissing key(s) in state_dict: \"encoder.embeds.1.weight\", \"encoder.embeds.2.weight\", \"encoder.embeds.3.weight\". \n\tsize mismatch for encoder.embeds.0.weight: copying a param with shape torch.Size([2, 14]) from checkpoint, the shape in current model is torch.Size([31, 8]).\n\tsize mismatch for encoder.layers.0.block.0.weight: copying a param with shape torch.Size([64, 27]) from checkpoint, the shape in current model is torch.Size([64, 36]).\n\tsize mismatch for decoder.reconstructed.weight: copying a param with shape torch.Size([27, 64]) from checkpoint, the shape in current model is torch.Size([36, 64]).\n\tsize mismatch for decoder.reconstructed.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([36])."
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of training, the total loss is around 0.8 (depending on the run). Let's see how this model performs on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a183b49ddcce4695a91495cb029d01e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Step must only increase in log calls.  Step 1 < 34247; dropping {'test_loss': 5.885089874267578, 'epoch': 1}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(5.8851)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 5.885089874267578}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer0.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test loss is close to the training loss, so we are not overfitting. We could probably improve on this loss by further optimising hyperparameters (WandB actually offers an easy framework for running hyperparameter optimisation by random, grid or Bayesian search). For now, let's go with these weights and see if the model can find outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>gap_holiday</th>\n",
       "      <th>t</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.472913</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.395093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.736216</td>\n",
       "      <td>-1.725462</td>\n",
       "      <td>0.025421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.404614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.431191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.736216</td>\n",
       "      <td>-1.725004</td>\n",
       "      <td>0.024593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.474927</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.491355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.736216</td>\n",
       "      <td>-1.724241</td>\n",
       "      <td>0.025160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.324889</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.551518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.736216</td>\n",
       "      <td>-1.723478</td>\n",
       "      <td>0.023980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.333131</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.599649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.736216</td>\n",
       "      <td>-1.722868</td>\n",
       "      <td>0.023252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value  day  month  hour_min  day_of_week  holiday  gap_holiday  \\\n",
       "0 -0.472913    1      2  1.395093            0        0    -1.736216   \n",
       "1 -0.404614    1      2  1.431191            0        0    -1.736216   \n",
       "2 -0.474927    1      2  1.491355            0        0    -1.736216   \n",
       "3 -0.324889    1      2  1.551518            0        0    -1.736216   \n",
       "4 -0.333131    1      2  1.599649            0        0    -1.736216   \n",
       "\n",
       "          t      loss  \n",
       "0 -1.725462  0.025421  \n",
       "1 -1.725004  0.024593  \n",
       "2 -1.724241  0.025160  \n",
       "3 -1.723478  0.023980  \n",
       "4 -1.722868  0.023252  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = VAE.load_from_checkpoint('./vae_weights.ckpt')\n",
    "trained_model.freeze()\n",
    "dataset = TSDataset('test', cont_vars=hparams.cont_vars, \n",
    "                    cat_vars=hparams.cat_vars,\n",
    "                    lbl_as_feat=True) \n",
    "losses = []\n",
    "# run predictions for the training set examples\n",
    "for i in range(len(dataset)):\n",
    "    x_cont, x_cat = dataset[i]\n",
    "    x_cont.unsqueeze_(0)\n",
    "    x_cat.unsqueeze_(0)\n",
    "    recon, mu, logvar, x = trained_model.forward((x_cont, x_cat))\n",
    "    recon_loss, kld = trained_model.loss_function(x, recon, mu, logvar)\n",
    "    losses.append(recon_loss + trained_model.hparams.kld_beta * kld)\n",
    "    \n",
    "data_with_losses = dataset.df\n",
    "data_with_losses['loss'] = np.asarray(losses)\n",
    "data_with_losses.sort_values('t', inplace=True)\n",
    "data_with_losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Ni Ying/Desktop/data/vae_weights.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-98b5ba1b5dad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrained_model0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Ni Ying/Desktop/data/vae_weights.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrained_model0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\fsspec\\spec.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, block_size, cache_options, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[0mautocommit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                 \u001b[0mcache_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m             )\n\u001b[0;32m    905\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"w\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, autocommit, fs, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautocommit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"w\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[1;31m# TODO: check if path is writable?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Ni Ying/Desktop/data/vae_weights.ckpt'"
     ]
    }
   ],
   "source": [
    "trained_model0 = VAE.load_from_checkpoint('C:/Users/Ni Ying/Desktop/data/vae_weights.ckpt')\n",
    "trained_model0.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSDataset('test', cont_vars=hparams.cont_vars, \n",
    "                    cat_vars=hparams.cat_vars,\n",
    "                    lbl_as_feat=True) \n",
    "losses = []\n",
    "# run predictions for the training set examples\n",
    "for i in range(len(dataset)):\n",
    "    x_cont, x_cat = dataset[i]\n",
    "    x_cont.unsqueeze_(0)\n",
    "    x_cat.unsqueeze_(0)\n",
    "    recon, mu, logvar, x = trained_model.forward((x_cont, x_cat))\n",
    "    recon_loss, kld = trained_model.loss_function(x, recon, mu, logvar)\n",
    "    losses.append(recon_loss + trained_model.hparams.kld_beta * kld)\n",
    "    \n",
    "data_with_losses = dataset.df\n",
    "data_with_losses['loss'] = np.asarray(losses)\n",
    "data_with_losses.sort_values('t', inplace=True)\n",
    "data_with_losses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are loss values distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.019997287541627884, 0.02263602800667286)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, sigma = data_with_losses['loss'].mean(), data_with_losses['loss'].std()\n",
    "mean, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a threshold value (in units of sigma) beyond which instances are classified as anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 6  # threshold for anomaly, in sigmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now flag as anomalies any instance where the loss is very far from the centre of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value  day  month  hour_min  day_of_week  holiday  gap_holiday  \\\n",
      "0 -0.472913    1      2  1.395093            0        0    -1.736216   \n",
      "1 -0.404614    1      2  1.431191            0        0    -1.736216   \n",
      "2 -0.474927    1      2  1.491355            0        0    -1.736216   \n",
      "3 -0.324889    1      2  1.551518            0        0    -1.736216   \n",
      "4 -0.333131    1      2  1.599649            0        0    -1.736216   \n",
      "\n",
      "          t      loss  anomaly  \n",
      "0 -1.725462  0.025421    False  \n",
      "1 -1.725004  0.024593    False  \n",
      "2 -1.724241  0.025160    False  \n",
      "3 -1.723478  0.023980    False  \n",
      "4 -1.722868  0.023252    False  \n"
     ]
    }
   ],
   "source": [
    "data_with_losses['anomaly'] = data_with_losses['loss'] > (mean + sigma * thresh)\n",
    "print(data_with_losses.head())\n",
    "colors = ['red' if anomaly else 'blue' for anomaly in data_with_losses['anomaly']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in a histogram. Red colour denotes abnormal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c44bdd7188>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAViElEQVR4nO3dfZBdVZnv8e+TgImCBU0SKSoBEqigkGohSRtSgoYpNAlURRgHhKkSIoOVUYk118sf4lgKalE1vtxRsRjHTBnSchGGK84Qb+HlRsKLaCLpYEjTvCQBArShQgxvMyKOgef+0Tu5J0mn+/Tpk37J+n6qdp191lnrnP30Dr/e7L17nchMJEllGDPcGyBJGjqGviQVxNCXpIIY+pJUEENfkgpy2HBvQF8mTpyYU6dObXj8+vX995k9u+G3l6QRaf369b/PzEm9vTaiQ3/q1Kl0dHQ0PD6i/z6DeHtJGpEi4tkDvebpHUkqiKEvSQUx9CWpICP6nL6kQ9Of//xnuru7eeONN4Z7U0a18ePHM2XKFA4//PC6xxj6koZcd3c373znO5k6dSpRzx0X2k9msnPnTrq7u5k2bVrd4zy9I2nIvfHGG0yYMMHAH4SIYMKECQP+vyVDX9KwMPAHr5GfoaEvSQUx9CUNu4jmLqPBOeecM6g/Pm2UoS9JA7Rr167h3oSGefeOpCJt3bqV8847j7PPPptf//rXTJ48mTvvvJMnn3yST33qU7z++uucfPLJLF++nJaWFs455xze//7386tf/YqPfOQjdHZ28va3v50nnniCZ599lptuuon29nbWrFnDmWeeyYoVKwD49Kc/zbp16/jjH//IRRddxFe+8pVhrdsjfUnF2rx5M1dddRVdXV0cffTR3HHHHVx++eV8/etfZ+PGjbS2tu4V0q+88gr3338/V199NQAvv/wyq1ev5tvf/jaLFi3ic5/7HF1dXXR2drJhwwYArr/+ejo6Oti4cSP3338/GzduHJZadzP0JRVr2rRpnHHGGQDMnj2bp556ildeeYV58+YBsHjxYh544IE9/S+55JK9xi9atIiIoLW1lWOPPZbW1lbGjBnDjBkz2Lp1KwC33347s2bNYubMmXR1dfHYY48NTXEH4OkdScUaN27cnvWxY8fyyiuv9Nn/iCOO6HX8mDFj9nqvMWPGsGvXLp555hm+9a1vsW7dOlpaWvjEJz4x7H+F7JG+JFWOOuooWlpa+OUvfwnAzTffvOeovxGvvfYaRxxxBEcddRTbt2/n5z//ebM2tWEe6UsadpnDvQX/X3t7+54LuSeddBI33XRTw+91+umnM3PmTGbMmMFJJ53EWWed1cQtbUzkSPpp76OtrS0P9peojODypUPW448/zqmnnjrcm3FI6O1nGRHrM7Ott/6e3pGkghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlDb8RMrfykUce2cSimmfFihUsXbq0Ke9l6EvSQTTSpmE29CUV6cILL2T27NnMmDGDZcuW7Wm/+uqrmTVrFueeey47duwAer7w5POf/zxz5szhlFNO2TNNwxtvvMEVV1xBa2srM2fO5N577wV6jswvvvhiFi1axPz587nvvvuYN28eH/vYxzjllFO45ppruOWWW5gzZw6tra089dRTAPzsZz/jzDPPZObMmXzoQx9i+/btTa/b0JdUpOXLl7N+/Xo6Ojq44YYb2LlzJ3/4wx+YNWsWDz/8MPPmzdtrWuVdu3bx0EMP8Z3vfGdP+4033ghAZ2cnt956K4sXL94zodqaNWtob29n9erVADzyyCN897vfpbOzk5tvvplNmzbx0EMP8clPfpLvfe97AJx99tmsXbuW3/72t1x66aV84xvfaHrd/YZ+RBwfEfdGxOMR0RURf1e1XxcRv4uIDdVyfs2YL0TEloh4MiIW1LQvrNq2RMQ1Ta9Gkup0ww03cPrppzN37lyef/55Nm/ezJgxY/ZMn/zxj3+cBx98cE//j370o0DPFMy7p01+8MEHueyyywB4z3vew4knnsimTZsA+PCHP8wxxxyzZ/z73vc+jjvuOMaNG8fJJ5/M/PnzAWhtbd3zft3d3SxYsIDW1la++c1v0tXV1fS66znS3wVcnZmnAnOBqyLitOq1b2fmGdVyF0D12qXADGAh8E8RMTYixgI3AucBpwF/XfM+kjRk7rvvPn7xi1+wZs0aHnnkEWbOnNnrlMdRc1F499TJY8eO3XOevq+5yw40DTPsPRXz7mmYAT772c+ydOlSOjs7+cEPfnBQpmHuN/Qz84XMfLha/w/gcWByH0MuAG7LzD9l5jPAFmBOtWzJzKcz87+A26q+kjSkXn31VVpaWnjHO97BE088wdq1awF46623+MlPfgLAj3/8Y84+++w+3+eDH/wgt9xyCwCbNm3iueee493vfvegtmvy5J54bW9vb/h9+jKgc/oRMRWYCfymaloaERsjYnlEtFRtk4Hna4Z1V20HapdUuszmLv1YuHAhu3bt4r3vfS9f+tKXmDt3LtBzdN7V1cXs2bNZvXo1X/7yl/t8n8985jO8+eabtLa2cskll7BixYq9jugH6rrrruPiiy/mAx/4ABMnTmz4ffpS99TKEXEkcD9wfWb+NCKOBX4PJPA14LjM/JuIuBFYk5n/sxr3Q+Auen7BLMjMT1btlwFzMvOz+3zOEmAJwAknnDD72Wefbbw4p1aWRiSnVm6egzK1ckQcDtwB3JKZPwXIzO2Z+WZmvgX8Cz2nb6DnCP74muFTgG19tO8lM5dlZltmtk2aNKmezZMk1ameu3cC+CHweGb+Y037cTXd/hJ4tFpfCVwaEeMiYhowHXgIWAdMj4hpEfE2ei72rmxOGZKketTzdYlnAZcBnRGxoWr7e3ruvjmDntM7W4G/BcjMroi4HXiMnjt/rsrMNwEiYilwNzAWWJ6Zzb8fSdKokJl73R2jgWvkmw/7Df3MfBDobc/c1ceY64Hre2m/q69xksowfvx4du7cyYQJEwz+BmUmO3fuZPz48QMa5xejSxpyU6ZMobu7e880B2rM+PHjmTJlyoDGGPqShtzhhx/OtGnThnsziuTcO5JUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgrSb+hHxPERcW9EPB4RXRHxd1X7MRGxKiI2V48tVXtExA0RsSUiNkbErJr3Wlz13xwRiw9eWZKk3tRzpL8LuDozTwXmAldFxGnANcA9mTkduKd6DnAeML1algDfh55fEsC1wJnAHODa3b8oJElDo9/Qz8wXMvPhav0/gMeBycAFQHvVrR24sFq/APhR9lgLHB0RxwELgFWZ+VJmvgysAhY2tRpJUp8GdE4/IqYCM4HfAMdm5gvQ84sBeFfVbTLwfM2w7qrtQO2SpCFSd+hHxJHAHcB/y8zX+uraS1v20b7v5yyJiI6I6NixY0e9mydJqkNdoR8Rh9MT+Ldk5k+r5u3VaRuqxxer9m7g+JrhU4BtfbTvJTOXZWZbZrZNmjRpILVIkvpRz907AfwQeDwz/7HmpZXA7jtwFgN31rRfXt3FMxd4tTr9czcwPyJaqgu486s2SdIQOayOPmcBlwGdEbGhavt74B+A2yPiSuA54OLqtbuA84EtwOvAFQCZ+VJEfA1YV/X7ama+1JQqJEl1icz9TquPGG1tbdnR0dHw+OjtKsI+RnD5ktSQiFifmW29veZf5EpSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKkg935F7SKvnKxXBr1WUdGjwSF+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQfoN/YhYHhEvRsSjNW3XRcTvImJDtZxf89oXImJLRDwZEQtq2hdWbVsi4prmlyJJ6k89R/orgIW9tH87M8+olrsAIuI04FJgRjXmnyJibESMBW4EzgNOA/666itJGkL9TriWmQ9ExNQ63+8C4LbM/BPwTERsAeZUr23JzKcBIuK2qu9jA95iSVLDBnNOf2lEbKxO/7RUbZOB52v6dFdtB2rfT0QsiYiOiOjYsWPHIDZPkrSvRkP/+8DJwBnAC8D/qNp7m6g4+2jfvzFzWWa2ZWbbpEmTGtw8SVJvGppPPzO3716PiH8B/nf1tBs4vqbrFGBbtX6gdknSEGnoSD8ijqt5+pfA7jt7VgKXRsS4iJgGTAceAtYB0yNiWkS8jZ6LvSsb32xJUiP6PdKPiFuBc4CJEdENXAucExFn0HOKZivwtwCZ2RURt9NzgXYXcFVmvlm9z1LgbmAssDwzu5pejSSpT5Ej+HsA29rasqOjo+Hx9X4VYj1G8I9JkvYSEeszs6231/yLXEkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBWk39CPiOUR8WJEPFrTdkxErIqIzdVjS9UeEXFDRGyJiI0RMatmzOKq/+aIWHxwypEk9aWeI/0VwMJ92q4B7snM6cA91XOA84Dp1bIE+D70/JIArgXOBOYA1+7+RSFJGjr9hn5mPgC8tE/zBUB7td4OXFjT/qPssRY4OiKOAxYAqzLzpcx8GVjF/r9IJEkHWaPn9I/NzBcAqsd3Ve2Tgedr+nVXbQdq309ELImIjojo2LFjR4ObJ0nqTbMv5EYvbdlH+/6Nmcsysy0z2yZNmtTUjZOk0jUa+tur0zZUjy9W7d3A8TX9pgDb+miXJA2hRkN/JbD7DpzFwJ017ZdXd/HMBV6tTv/cDcyPiJbqAu78qk2SNIQO669DRNwKnANMjIhueu7C+Qfg9oi4EngOuLjqfhdwPrAFeB24AiAzX4qIrwHrqn5fzcx9Lw5Lkg6yyOz11PqI0NbWlh0dHQ2Pj96uJDRoBP+YJGkvEbE+M9t6e82/yJWkghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBBhX6EbE1IjojYkNEdFRtx0TEqojYXD22VO0RETdExJaI2BgRs5pRwFCJ6H+RpJGuGUf6f5GZZ2RmW/X8GuCezJwO3FM9BzgPmF4tS4DvN+GzJUkDcDBO71wAtFfr7cCFNe0/yh5rgaMj4riD8PmSpAMYbOgn8H8jYn1ELKnajs3MFwCqx3dV7ZOB52vGdldte4mIJRHREREdO3bsGOTmDa16TgHVu0jSwXDYIMeflZnbIuJdwKqIeKKPvr1FWe7XkLkMWAbQ1ta23+uSpMYN6kg/M7dVjy8C/wbMAbbvPm1TPb5Yde8Gjq8ZPgXYNpjPlyQNTMOhHxFHRMQ7d68D84FHgZXA4qrbYuDOan0lcHl1F89c4NXdp4EkSUNjMKd3jgX+LXpOQB8G/Dgz/09ErANuj4grgeeAi6v+dwHnA1uA14ErBvHZkqQGNBz6mfk0cHov7TuBc3tpT+CqRj9PkjR4/kWuJBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIMdmplHST1zqmfTj4taQA80pekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIs2yOcvXMxulMnJJ280hfkgpi6EtSQTy9UwC/kEXSbkN+pB8RCyPiyYjYEhHXDPXnq2wR/S/SoWxIj/QjYixwI/BhoBtYFxErM/OxodwO9a6ZF4WbGZ71fGYzP8//M9KhbKhP78wBtmTm0wARcRtwAWDojxLDcSQ8Uo++vXNKo9FQh/5k4Pma593AmbUdImIJsKR6+p8R8WQDnzMR+H1DWzh6WOMoUMcvhlFfYx1KqBFGVp0nHuiFoQ793v4T2OtYKDOXAcsG9SERHZnZNpj3GOms8dBgjYeO0VLnUF/I7QaOr3k+Bdg2xNsgScUa6tBfB0yPiGkR8TbgUmDlEG+DJBVrSE/vZOauiFgK3A2MBZZnZtdB+KhBnR4aJazx0GCNh45RUWektxdIUjGchkGSCmLoS1JBRlXo9zeFQ0SMi4h/rV7/TURMrXntC1X7kxGxYCi3eyAarTEipkbEHyNiQ7X881Bv+0DUUecHI+LhiNgVERft89riiNhcLYuHbqsHZpA1vlmzL0fszQ511PjfI+KxiNgYEfdExIk1rx0q+7GvGkfefszMUbHQc+H3KeAk4G3AI8Bp+/T5DPDP1fqlwL9W66dV/ccB06r3GTvcNTW5xqnAo8NdQxPrnAq8F/gRcFFN+zHA09VjS7XeMtw1NbPG6rX/HO4amlTjXwDvqNY/XfPv9VDaj73WOFL342g60t8zhUNm/hewewqHWhcA7dX6T4BzIyKq9tsy80+Z+QywpXq/kWYwNY4m/daZmVszcyPw1j5jFwCrMvOlzHwZWAUsHIqNHqDB1Dha1FPjvZn5evV0LT1/mwOH1n48UI0j0mgK/d6mcJh8oD6ZuQt4FZhQ59iRYDA1AkyLiN9GxP0R8YGDvbGDMJj9cSjty76Mj4iOiFgbERc2d9OaZqA1Xgn8vMGxw2UwNcII3I+jaT79fqdw6KNPPWNHgsHU+AJwQmbujIjZwL9HxIzMfK3ZG9kEg9kfh9K+7MsJmbktIk4CVkdEZ2Y+1aRta5a6a4yIjwNtwLyBjh1mg6kRRuB+HE1H+vVM4bCnT0QcBhwFvFTn2JGg4RqrU1c7ATJzPT3nIU856FvcmMHsj0NpXx5QZm6rHp8G7gNmNnPjmqSuGiPiQ8AXgY9k5p8GMnYEGEyNI3M/DvdFhXoXev6v5Gl6LsTuvqAyY58+V7H3Rc7bq/UZ7H0h92lG5oXcwdQ4aXdN9Fx0+h1wzHDX1GidNX1XsP+F3GfoufjXUq2PuDoHWWMLMK5anwhsZp+LhyNhqfPf60x6DkCm79N+yOzHPmockftx2H+oA9wB5wObqh/wF6u2r9Lz2xVgPPC/6LlQ+xBwUs3YL1bjngTOG+5aml0j8FdAV/WP8mFg0XDXMsg630fPUdYfgJ1AV83Yv6nq3wJcMdy1NLtG4P1AZ7UvO4Erh7uWQdT4C2A7sKFaVh6C+7HXGkfqfnQaBkkqyGg6py9JGiRDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXk/wH/4C4/klquqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies_loss = data_with_losses.loc[data_with_losses['anomaly'], 'loss']\n",
    "normals_loss   = data_with_losses.loc[~data_with_losses['anomaly'], 'loss']\n",
    "plt.hist([normals_loss, anomalies_loss], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'abnormal'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean in terms of the distribution of the temperature values? We first \"unscale\" the data to put each feature back into the value ranges of the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       value  day  month   hour_min  day_of_week  holiday  gap_holiday  \\\n",
      "0  79.329836    2     12  21.583333            0        0        -23.0   \n",
      "1  80.272828    2     12  21.833333            0        0        -23.0   \n",
      "2  79.302033    2     12  22.250000            0        0        -23.0   \n",
      "3  81.373575    2     12  22.666667            0        0        -23.0   \n",
      "4  81.259781    2     12  23.000000            0        0        -23.0   \n",
      "\n",
      "            t      loss  anomaly  \n",
      "0  13860201.0  0.025421    False  \n",
      "1  13860210.0  0.024593    False  \n",
      "2  13860225.0  0.025160    False  \n",
      "3  13860240.0  0.023980    False  \n",
      "4  13860252.0  0.023252    False  \n"
     ]
    }
   ],
   "source": [
    "data_with_losses_unscaled = data_with_losses.copy()\n",
    "data_with_losses_unscaled[cont_vars] = scaler.inverse_transform(data_with_losses[cont_vars])\n",
    "for enc, var in zip(label_encoders, cat_vars):\n",
    "    data_with_losses_unscaled[var] = enc.inverse_transform(data_with_losses[var])\n",
    "data_with_losses_unscaled = pd.DataFrame(data_with_losses_unscaled, columns=data_with_losses.columns)\n",
    "print(data_with_losses_unscaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>gap_holiday</th>\n",
       "      <th>t</th>\n",
       "      <th>loss</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.329836</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860201.0</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.272828</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860210.0</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.302033</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860225.0</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.373575</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860240.0</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.259781</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>13860252.0</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>94.657280</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928172.0</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>95.377308</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928175.0</td>\n",
       "      <td>0.049483</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>97.184352</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928187.0</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>97.549774</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928214.0</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>97.804168</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13928226.0</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6809 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          value  day  month   hour_min  day_of_week  holiday  gap_holiday  \\\n",
       "0     79.329836    2     12  21.583333            0        0        -23.0   \n",
       "1     80.272828    2     12  21.833333            0        0        -23.0   \n",
       "2     79.302033    2     12  22.250000            0        0        -23.0   \n",
       "3     81.373575    2     12  22.666667            0        0        -23.0   \n",
       "4     81.259781    2     12  23.000000            0        0        -23.0   \n",
       "...         ...  ...    ...        ...          ...      ...          ...   \n",
       "6804  94.657280   19      2  13.666667            2        0         49.0   \n",
       "6805  95.377308   19      2  13.750000            2        0         49.0   \n",
       "6806  97.184352   19      2  14.083333            2        0         49.0   \n",
       "6807  97.549774   19      2  14.833333            2        0         49.0   \n",
       "6808  97.804168   19      2  15.166667            2        0         49.0   \n",
       "\n",
       "               t      loss  anomaly  \n",
       "0     13860201.0  0.025421    False  \n",
       "1     13860210.0  0.024593    False  \n",
       "2     13860225.0  0.025160    False  \n",
       "3     13860240.0  0.023980    False  \n",
       "4     13860252.0  0.023252    False  \n",
       "...          ...       ...      ...  \n",
       "6804  13928172.0  0.048355    False  \n",
       "6805  13928175.0  0.049483    False  \n",
       "6806  13928187.0  0.053763    False  \n",
       "6807  13928214.0  0.056864    False  \n",
       "6808  13928226.0  0.058625    False  \n",
       "\n",
       "[6809 rows x 10 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_losses_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the histogram of `values`, coloured depending on whether or not the loss value for the corresponding observations are considered abnormal or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c44e2183c8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies_value = data_with_losses_unscaled.loc[data_with_losses_unscaled['anomaly'], ['loss','value']]\n",
    "normals_value = data_with_losses_unscaled.loc[~data_with_losses_unscaled['anomaly'], ['loss','value']]\n",
    "\n",
    "plt.hist([normals_value['value'], anomalies_value['value']], bins=100, stacked=True, color=['blue', 'red'], label=['normal', 'abnormal'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to note that the instances flagged as abnormal are not necessarily at the extreme end of the value spectrum, as they would be using a more naive approach. Let see these flagged examples on the original timeseries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               t      value\n",
      "1141  13872081.0  40.461427\n",
      "1142  13872087.0  36.249653\n",
      "1143  13872096.0  30.699649\n",
      "1144  13872111.0  22.983839\n",
      "1145  13872114.0  21.737032\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies_ts = data_with_losses_unscaled.loc[data_with_losses_unscaled['anomaly'], ('t', 'value')]\n",
    "holidays_ts = data_with_losses_unscaled.loc[data_with_losses_unscaled['holiday'] == 1, ('t', 'value')]\n",
    "print(anomalies_ts.head())\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_with_losses_unscaled['t'], data_with_losses_unscaled['value'], color='blue')\n",
    "ax.scatter(anomalies_ts['t'], anomalies_ts['value'], color='red', label='anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a shreshold at 6 sigmas, our model detects the first anomaly (the voluntary system shutdown) as well as the third one (catastrophic failure). It misses the second one but does not generate many false positives. The threshold that we defined can be adjusted to favour precision or recall and the optimal value could be determined by the area under the precision-recall curve. It would also be interesting to perform an ablation study to understand which of the engineered features are the most helpful.\n",
    "\n",
    "I hope this notebook was informative and gave you some insight into VAEs and their usefulness!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\\[1\\] Doersch, C. (2016). Tutorial on variational autoencoders. arXiv preprint arXiv:1606.05908.  \n",
    "\\[2\\] Ahmad, S., Lavin, A., Purdy, S., & Agha, Z. (2017). Unsupervised real-time anomaly detection for streaming data. Neurocomputing, 262, 134-147."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
