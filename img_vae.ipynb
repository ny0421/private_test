{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = Path('C:/Users/Ni Ying/Desktop/data/imagexlsx.xlsx')\n",
    "datasets_root = Path('C:/Users/Ni Ying/Desktop/data/working')\n",
    "data = pd.read_excel(datafile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "cat_vars = ['type','ifpic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>ifpic</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>asm</th>\n",
       "      <th>con</th>\n",
       "      <th>eng</th>\n",
       "      <th>idm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>166.841925</td>\n",
       "      <td>63.446047</td>\n",
       "      <td>-62.451236</td>\n",
       "      <td>158.253300</td>\n",
       "      <td>63.790080</td>\n",
       "      <td>-66.556483</td>\n",
       "      <td>156.180375</td>\n",
       "      <td>63.584990</td>\n",
       "      <td>-65.435522</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>2.5806</td>\n",
       "      <td>2.895655</td>\n",
       "      <td>0.843625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>111.179400</td>\n",
       "      <td>62.839314</td>\n",
       "      <td>-49.312123</td>\n",
       "      <td>155.679775</td>\n",
       "      <td>55.865453</td>\n",
       "      <td>-58.168950</td>\n",
       "      <td>187.076875</td>\n",
       "      <td>57.550191</td>\n",
       "      <td>-67.406039</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>4.2790</td>\n",
       "      <td>3.882789</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63658</th>\n",
       "      <td>1817710</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>88.309425</td>\n",
       "      <td>59.678349</td>\n",
       "      <td>53.144456</td>\n",
       "      <td>72.491300</td>\n",
       "      <td>46.649307</td>\n",
       "      <td>43.335417</td>\n",
       "      <td>56.603550</td>\n",
       "      <td>44.023987</td>\n",
       "      <td>42.715452</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>3.480351</td>\n",
       "      <td>0.758520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63659</th>\n",
       "      <td>1817712</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63660</th>\n",
       "      <td>1817890</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>187.832400</td>\n",
       "      <td>73.076020</td>\n",
       "      <td>-76.987670</td>\n",
       "      <td>155.453025</td>\n",
       "      <td>55.151594</td>\n",
       "      <td>-33.555261</td>\n",
       "      <td>89.282200</td>\n",
       "      <td>55.796176</td>\n",
       "      <td>50.441616</td>\n",
       "      <td>0.038189</td>\n",
       "      <td>2.9433</td>\n",
       "      <td>3.854994</td>\n",
       "      <td>0.730024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63661</th>\n",
       "      <td>1823090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204.942675</td>\n",
       "      <td>41.241178</td>\n",
       "      <td>-37.723090</td>\n",
       "      <td>121.325050</td>\n",
       "      <td>43.164924</td>\n",
       "      <td>25.844677</td>\n",
       "      <td>86.205650</td>\n",
       "      <td>32.699973</td>\n",
       "      <td>-16.954191</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>1.0046</td>\n",
       "      <td>3.640017</td>\n",
       "      <td>0.741229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63662</th>\n",
       "      <td>1825048</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63663 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  type  ifpic          r1         r2         r3          g1  \\\n",
       "0            1     2      1  166.841925  63.446047 -62.451236  158.253300   \n",
       "1           12     2      1  111.179400  62.839314 -49.312123  155.679775   \n",
       "2           18     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "3           22     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "4           35     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "...        ...   ...    ...         ...        ...        ...         ...   \n",
       "63658  1817710     2      1   88.309425  59.678349  53.144456   72.491300   \n",
       "63659  1817712     2      0    0.000000   0.000000   0.000000    0.000000   \n",
       "63660  1817890     2      1  187.832400  73.076020 -76.987670  155.453025   \n",
       "63661  1823090     1      1  204.942675  41.241178 -37.723090  121.325050   \n",
       "63662  1825048     1      0    0.000000   0.000000   0.000000    0.000000   \n",
       "\n",
       "              g2         g3          b1         b2         b3       asm  \\\n",
       "0      63.790080 -66.556483  156.180375  63.584990 -65.435522  0.179038   \n",
       "1      55.865453 -58.168950  187.076875  57.550191 -67.406039  0.049059   \n",
       "2       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "3       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "4       0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "...          ...        ...         ...        ...        ...       ...   \n",
       "63658  46.649307  43.335417   56.603550  44.023987  42.715452  0.056898   \n",
       "63659   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "63660  55.151594 -33.555261   89.282200  55.796176  50.441616  0.038189   \n",
       "63661  43.164924  25.844677   86.205650  32.699973 -16.954191  0.039200   \n",
       "63662   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "\n",
       "          con       eng       idm  \n",
       "0      2.5806  2.895655  0.843625  \n",
       "1      4.2790  3.882789  0.663226  \n",
       "2      0.0000  0.000000  0.000000  \n",
       "3      0.0000  0.000000  0.000000  \n",
       "4      0.0000  0.000000  0.000000  \n",
       "...       ...       ...       ...  \n",
       "63658  0.9922  3.480351  0.758520  \n",
       "63659  0.0000  0.000000  0.000000  \n",
       "63660  2.9433  3.854994  0.730024  \n",
       "63661  1.0046  3.640017  0.741229  \n",
       "63662  0.0000  0.000000  0.000000  \n",
       "\n",
       "[63663 rows x 16 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = [LabelEncoder() for _ in cat_vars] \n",
    "for col, enc in zip(cat_vars, label_encoders):\n",
    "    data[col] = enc.fit_transform(data[col])\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_data = data[data['type']==2]\n",
    "tst_data = pri_data\n",
    "off_data = data[data['type']==0]\n",
    "plat_data = data[data['type']==1]\n",
    "tr_data = pd.concat((off_data, plat_data), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(tr_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled = tr_data.copy()\n",
    "tr_data_scaled[cont_vars] = scaler.transform(tr_data[cont_vars])\n",
    "tst_data_scaled = tst_data.copy()\n",
    "tst_data_scaled[cont_vars] = scaler.transform(tst_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          uid  type  ifpic          r1          r2          r3          g1  \\\n",
       " 0        5719     0      1   78.896825   74.612187   39.078860   54.869900   \n",
       " 1        6719     0      1  182.745225  108.374545 -107.900955  195.247175   \n",
       " 2        7179     0      1   64.799700   58.491642   71.718025   80.051075   \n",
       " 3        7207     0      1  224.493475   16.922179  -17.684040  202.285325   \n",
       " 4        7257     0      0    0.000000    0.000000    0.000000    0.000000   \n",
       " ...       ...   ...    ...         ...         ...         ...         ...   \n",
       " 3767  1808066     1      0    0.000000    0.000000    0.000000    0.000000   \n",
       " 3768  1808828     1      0    0.000000    0.000000    0.000000    0.000000   \n",
       " 3769  1809348     1      0    0.000000    0.000000    0.000000    0.000000   \n",
       " 3770  1823090     1      1  204.942675   41.241178  -37.723090  121.325050   \n",
       " 3771  1825048     1      0    0.000000    0.000000    0.000000    0.000000   \n",
       " \n",
       "              g2         g3          b1         b2         b3       asm  \\\n",
       " 0     49.705432  -8.276585   23.881725  23.460473  22.432648  0.189662   \n",
       " 1     85.291743 -80.432292  212.582450  62.767672 -67.207104  0.409124   \n",
       " 2     68.668376  78.536762  101.821675  77.887469  74.833777  0.119673   \n",
       " 3     30.294557 -26.095023  167.392700  43.293536 -33.097670  0.080244   \n",
       " 4      0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       " ...         ...        ...         ...        ...        ...       ...   \n",
       " 3767   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       " 3768   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       " 3769   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       " 3770  43.164924  25.844677   86.205650  32.699973 -16.954191  0.039200   \n",
       " 3771   0.000000   0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       " \n",
       "          con       eng       idm  \n",
       " 0     3.6392  2.703286  0.795945  \n",
       " 1     4.1468  1.564471  0.889403  \n",
       " 2     0.6236  2.889069  0.869746  \n",
       " 3     0.4576  2.881979  0.851102  \n",
       " 4     0.0000  0.000000  0.000000  \n",
       " ...      ...       ...       ...  \n",
       " 3767  0.0000  0.000000  0.000000  \n",
       " 3768  0.0000  0.000000  0.000000  \n",
       " 3769  0.0000  0.000000  0.000000  \n",
       " 3770  1.0046  3.640017  0.741229  \n",
       " 3771  0.0000  0.000000  0.000000  \n",
       " \n",
       " [3772 rows x 16 columns],\n",
       "           uid  type  ifpic        r1        r2        r3        g1        g2  \\\n",
       " 0        5719     0      1 -0.305752  1.227966  1.444914 -0.474961  0.348039   \n",
       " 1        6719     0      1  0.656434  2.168581 -1.901661  0.925902  1.302675   \n",
       " 2        7179     0      1 -0.436365  0.778850  2.188073 -0.223671  0.856737   \n",
       " 3        7207     0      1  1.043243 -0.379270  0.152483  0.996138 -0.172676   \n",
       " 4        7257     0      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       " ...       ...   ...    ...       ...       ...       ...       ...       ...   \n",
       " 3767  1808066     1      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       " 3768  1808828     1      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       " 3769  1809348     1      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       " 3770  1823090     1      1  0.862100  0.298254 -0.303785  0.188213  0.172584   \n",
       " 3771  1825048     1      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       " \n",
       "             g3        b1        b2        b3       asm       con       eng  \\\n",
       " 0     0.344507 -0.755868 -0.394689  0.952432 -0.071256  0.358006  1.300065   \n",
       " 1    -1.220392  1.162140  0.578196 -0.835028  0.890469  0.503087  0.338017   \n",
       " 2     2.227297  0.036336  0.952423  1.997335 -0.377961 -0.503907  1.457011   \n",
       " 3    -0.041936  0.702818  0.096196 -0.154870 -0.550744 -0.551353  1.451022   \n",
       " 4     0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 3767  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       " 3768  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       " 3769  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       " 3770  1.084522 -0.122390 -0.166004  0.167039 -0.730607 -0.395010  2.091398   \n",
       " 3771  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       " \n",
       "            idm  \n",
       " 0     0.811984  \n",
       " 1     1.036325  \n",
       " 2     0.989140  \n",
       " 3     0.944385  \n",
       " 4    -1.098656  \n",
       " ...        ...  \n",
       " 3767 -1.098656  \n",
       " 3768 -1.098656  \n",
       " 3769 -1.098656  \n",
       " 3770  0.680638  \n",
       " 3771 -1.098656  \n",
       " \n",
       " [3772 rows x 16 columns])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, tr_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled.to_csv(datasets_root/'img_ad_train.csv', index=False)\n",
    "tst_data_scaled.to_csv(datasets_root/'img_ad_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset(Dataset):\n",
    "    def __init__(self, split, cont_vars=None, cat_vars=None, lbl_as_feat=True):\n",
    "        \"\"\"\n",
    "        split: 'train' if we want to get data from the training examples, 'test' for\n",
    "        test examples, or 'both' to merge the training and test sets and return samples\n",
    "        from either.\n",
    "        cont_vars: List of continuous variables to return as features. If None, returns\n",
    "        all continuous variables available.\n",
    "        cat_vars: Same as above, but for categorical variables.\n",
    "        lbl_as_feat: Set to True when training a VAE -- the labels (temperature values)\n",
    "        will be included as another dimension of the data. Set to False when training\n",
    "        a model to predict temperatures.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert split in ['train', 'test', 'both']\n",
    "        self.lbl_as_feat = lbl_as_feat\n",
    "        if split == 'train':\n",
    "            self.df = pd.read_csv(datasets_root/'img_ad_train.csv')\n",
    "        elif split == 'test':\n",
    "            self.df = pd.read_csv(datasets_root/'img_ad_test.csv')\n",
    "        else:\n",
    "            df1 = pd.read_csv(datasets_root/'img_ad_train.csv')\n",
    "            df2 = pd.read_csv(datasets_root/'img_ad_test.csv')\n",
    "            self.df = pd.concat((df1, df2), ignore_index=True)\n",
    "        \n",
    "        if cat_vars:\n",
    "            self.cont_vars = cont_vars\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cont_vars = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "\n",
    "        # Select categorical variables to use\n",
    "        if cat_vars:\n",
    "            self.cat_vars = cat_vars\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cat_vars = ['ifpic']\n",
    "        \n",
    "        # Finally, make two Numpy arrays for continuous and categorical\n",
    "        # variables, respectively:\n",
    "        if self.lbl_as_feat:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "            self.lbl = self.df['type'].copy().to_numpy(dtype=np.float32)\n",
    "        self.cat = self.df[self.cat_vars].copy().to_numpy(dtype=np.int64)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if self.lbl_as_feat:  # for VAE training\n",
    "            return torch.tensor(self.cont[idx]), torch.tensor(self.cat[idx])\n",
    "        else:  # for supervised prediction\n",
    "            return torch.tensor(self.cont[idx]), torch.tensor(self.cat[idx]), torch.tensor(self.lbl[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63663\n",
      "(tensor([-0.3058,  1.2280,  1.4449, -0.4750,  0.3480,  0.3445, -0.7559, -0.3947,\n",
      "         0.9524, -0.0713,  0.3580,  1.3001,  0.8120]), tensor([1]))\n",
      "(tensor([ 0.6564,  2.1686, -1.9017,  0.9259,  1.3027, -1.2204,  1.1621,  0.5782,\n",
      "        -0.8350,  0.8905,  0.5031,  0.3380,  1.0363]), tensor([1]))\n",
      "(tensor([-0.4364,  0.7788,  2.1881, -0.2237,  0.8567,  2.2273,  0.0363,  0.9524,\n",
      "         1.9973, -0.3780, -0.5039,  1.4570,  0.9891]), tensor([1]))\n",
      "(tensor([ 1.0432, -0.3793,  0.1525,  0.9961, -0.1727, -0.0419,  0.7028,  0.0962,\n",
      "        -0.1549, -0.5507, -0.5514,  1.4510,  0.9444]), tensor([1]))\n",
      "(tensor([-1.0368, -0.8507,  0.5551, -1.0225, -0.9854,  0.5240, -0.9986, -0.9754,\n",
      "         0.5051, -0.9024, -0.6821, -0.9836, -1.0987]), tensor([0]))\n",
      "(tensor([ 0.5603,  1.3976, -1.2418,  0.5729,  1.3385, -1.0672,  0.5725,  1.1837,\n",
      "        -0.8828, -0.6256, -0.1243,  2.1297,  0.7058]), tensor([1]))\n",
      "(tensor([ 1.1636, -0.1395, -0.2110,  1.0016,  0.2758, -0.8483,  0.1090,  0.0432,\n",
      "         1.4338,  0.6405,  0.1257,  0.9524,  0.7664]), tensor([1]))\n",
      "(tensor([-1.0368, -0.8507,  0.5551, -1.0225, -0.9854,  0.5240, -0.9986, -0.9754,\n",
      "         0.5051, -0.9024, -0.6821, -0.9836, -1.0987]), tensor([0]))\n",
      "(tensor([-1.0368, -0.8507,  0.5551, -1.0225, -0.9854,  0.5240, -0.9986, -0.9754,\n",
      "         0.5051, -0.9024, -0.6821, -0.9836, -1.0987]), tensor([0]))\n",
      "(tensor([ 0.1931,  1.3390,  0.2670,  0.2174,  1.2909,  1.5125,  0.1664,  1.0727,\n",
      "         1.6536, -0.7218, -0.0710,  2.2910,  0.6399]), tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "ds = TSDataset(split='both', cont_vars=['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm'], cat_vars=['ifpic'], lbl_as_feat=True)\n",
    "print(len(ds))\n",
    "it = iter(ds)\n",
    "for _ in range(10):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    '''\n",
    "    A single fully connected layer with optional batch normalisation and activation.\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, bn = True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, out_dim)]\n",
    "        if bn: layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    The encoder part of our VAE. Takes a data sample and returns the mean and the log-variance of the \n",
    "    latent vector's distribution.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeds = nn.ModuleList([\n",
    "            nn.Embedding(n_cats, emb_size) for (n_cats, emb_size) in hparams.embedding_sizes\n",
    "        ])\n",
    "        # The input to the first layer is the concatenation of all embedding vectors and continuous\n",
    "        # values\n",
    "        in_dim = sum(emb.embedding_dim for emb in self.embeds) + len(hparams.cont_vars)\n",
    "        layer_dims = [in_dim] + [int(s) for s in hparams.layer_sizes.split(',')]\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(layer_dims[i], layer_dims[i + 1], bn) for i in range(len(layer_dims) - 1)],\n",
    "        )\n",
    "        self.mu = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "        self.logvar = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "    \n",
    "    def forward(self, x_cont, x_cat):\n",
    "        x_embed = [e(x_cat[:, i]) for i, e in enumerate(self.embeds)]        \n",
    "        x_embed = torch.cat(x_embed, dim=1)\n",
    "        x = torch.cat((x_embed, x_cont), dim=1)\n",
    "        h = self.layers(x)\n",
    "        mu_ = self.mu(h)\n",
    "        logvar_ = self.logvar(h)\n",
    "        return mu_, logvar_, x  # we return the concatenated input vector for use in loss fn\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    The decoder part of our VAE. Takes a latent vector (sampled from the distribution learned by the \n",
    "    encoder) and converts it back to a reconstructed data sample.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "#         self.final_activ = hparams.final_activ\n",
    "        hidden_dims = [hparams.latent_dim] + [int(s) for s in reversed(hparams.layer_sizes.split(','))]\n",
    "        out_dim = sum(emb_size for _, emb_size in hparams.embedding_sizes) + len(hparams.cont_vars)\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(hidden_dims[i], hidden_dims[i + 1], bn) for i in range(len(hidden_dims) - 1)],\n",
    "        )\n",
    "        self.reconstructed = nn.Linear(hidden_dims[-1], out_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = self.layers(z)\n",
    "        recon = self.reconstructed(h)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        if isinstance(hparams, dict):\n",
    "            hparams = Namespace(**hparams)\n",
    "        self.hparams = hparams\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.stdev = hparams.stdev\n",
    "        self.kld_beta = hparams.kld_beta\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.weight_decay\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        '''\n",
    "        The reparameterisation trick allows us to backpropagate through the encoder.\n",
    "        '''\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std) * self.stdev\n",
    "            return eps * std + mu\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x_cont, x_cat = batch\n",
    "        assert x_cat.dtype == torch.int64\n",
    "        mu, logvar, x = self.encoder(x_cont, x_cat)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, mu, logvar, x\n",
    "        \n",
    "    def loss_function(self, obs, recon, mu, logvar):\n",
    "#         recon_loss = F.mse_loss(recon, obs, reduction='sum')\n",
    "        recon_loss = F.smooth_l1_loss(recon, obs, reduction='sum')\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp())\n",
    "        return recon_loss, kld\n",
    "                               \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        # The loss function compares the concatenated input vector including\n",
    "        # embeddings to the reconstructed vector\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "\n",
    "        self.log('total_tr_loss', loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('recon_loss', recon_loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('kld', kld.mean(dim=0), on_step=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, \n",
    "                                weight_decay=self.hparams.weight_decay, \n",
    "                                eps=1e-4)\n",
    "        sch = torch.optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda epoch: 0.95)\n",
    "        return opt\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TSDataset('train', cont_vars=self.hparams.cont_vars, \n",
    "                            cat_vars = self.hparams.cat_vars, lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        dataset = TSDataset('test', cont_vars=self.hparams.cont_vars,\n",
    "                            cat_vars=self.hparams.cat_vars, lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled=pd.read_csv(datasets_root/'img_ad_train.csv')\n",
    "tst_data_scaled=pd.read_csv(datasets_root/'img_ad_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = ['r1','r2','r3','g1','g2','g3','b1','b2','b3','asm','con','eng','idm']\n",
    "cat_features = ['ifpic'] \n",
    "\n",
    "embed_cats = [len(tr_data_scaled[c].unique()) for c in cat_features]\n",
    "\n",
    "hparams = OrderedDict(\n",
    "    run='img_vars_embsz8_latsz32_bsz64_lay64-128-64_ep50',\n",
    "    cont_vars = cont_features,\n",
    "    cat_vars = cat_features,\n",
    "    embedding_sizes = [(embed_cats[i], 14) for i in range(len(embed_cats))],\n",
    "    latent_dim = 32,\n",
    "    layer_sizes = '64,128,64',\n",
    "    batch_norm = True,\n",
    "    stdev = 0.01,\n",
    "    kld_beta = 0.2,\n",
    "    lr = 0.01,\n",
    "    weight_decay = 1e-5,\n",
    "    batch_size = 64,\n",
    "    epochs = 200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('run', 'img_vars_embsz8_latsz32_bsz64_lay64-128-64_ep50'),\n",
       "             ('cont_vars',\n",
       "              ['r1',\n",
       "               'r2',\n",
       "               'r3',\n",
       "               'g1',\n",
       "               'g2',\n",
       "               'g3',\n",
       "               'b1',\n",
       "               'b2',\n",
       "               'b3',\n",
       "               'asm',\n",
       "               'con',\n",
       "               'eng',\n",
       "               'idm']),\n",
       "             ('cat_vars', ['ifpic']),\n",
       "             ('embedding_sizes', [(2, 14)]),\n",
       "             ('latent_dim', 32),\n",
       "             ('layer_sizes', '64,128,64'),\n",
       "             ('batch_norm', True),\n",
       "             ('stdev', 0.01),\n",
       "             ('kld_beta', 0.2),\n",
       "             ('lr', 0.01),\n",
       "             ('weight_decay', 1e-05),\n",
       "             ('batch_size', 64),\n",
       "             ('epochs', 200)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "# Simulate a Namespace with the defined hyperparameters\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VAE(hparams)\n",
    "logger = WandbLogger(name=hparams.run, project='img_ad_VAE_Anomaly', version=hparams.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 23.1 K\n",
      "1 | decoder | Decoder | 21.0 K\n",
      "------------------------------------\n",
      "44.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.0 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfe76c6e8a6471db1145e7fc9ff11ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.006918309709189364\n"
     ]
    }
   ],
   "source": [
    "ckpt_callback = pl.callbacks.ModelCheckpoint(filepath='C:/Users/Ni Ying/Desktop/data/img_ad_vae_weights')\n",
    "# Replace argument logger by None if you don't have a WandB account (and don't want to create one)\n",
    "trainer = pl.Trainer(gpus=None,logger=logger, max_epochs=hparams.epochs, \n",
    "                     auto_lr_find=True, benchmark=True, callbacks=[ckpt_callback],\n",
    "                     gradient_clip_val=1.\n",
    "                     )\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1yx0gslo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12500<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>D:\\Python_Program\\vae_anomaly_detection-main\\wandb\\run-20201215_005026-1yx0gslo\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>D:\\Python_Program\\vae_anomaly_detection-main\\wandb\\run-20201215_005026-1yx0gslo\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>total_tr_loss</td><td>13.57512</td></tr><tr><td>recon_loss</td><td>12.91878</td></tr><tr><td>kld</td><td>3.2817</td></tr><tr><td>_step</td><td>2947</td></tr><tr><td>_runtime</td><td>312</td></tr><tr><td>_timestamp</td><td>1607964961</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>total_tr_loss</td><td>▂▃█▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>recon_loss</td><td>▂▃█▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁▁▁▂▁▁▁</td></tr><tr><td>kld</td><td>▄▅█▄▃▂▃▂▂▂▁▂▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">zesty-breeze-1</strong>: <a href=\"https://wandb.ai/ny0421/VAE_Anomaly_img_ad/runs/1yx0gslo\" target=\"_blank\">https://wandb.ai/ny0421/VAE_Anomaly_img_ad/runs/1yx0gslo</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1yx0gslo). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">golden-plasma-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ny0421/VAE_Anomaly_img_ad\" target=\"_blank\">https://wandb.ai/ny0421/VAE_Anomaly_img_ad</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ny0421/VAE_Anomaly_img_ad/runs/3j7454wu\" target=\"_blank\">https://wandb.ai/ny0421/VAE_Anomaly_img_ad/runs/3j7454wu</a><br/>\n",
       "                Run data is saved locally in <code>D:\\Python_Program\\vae_anomaly_detection-main\\wandb\\run-20201215_005601-3j7454wu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3j7454wu)</h1><p></p><iframe src=\"https://wandb.ai/ny0421/VAE_Anomaly_img_ad/runs/3j7454wu\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1fc9eae0988>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='VAE_Anomaly_img_ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 23.1 K\n",
      "1 | decoder | Decoder | 21.0 K\n",
      "------------------------------------\n",
      "44.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.0 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e72f9b5e1b4498a8a13226f226de086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b1ec70e3dd4168a7f52375b0731a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Step must only increase in log calls.  Step 11742 < 11797; dropping {'test_loss': 8.66108512878418, 'epoch': 199}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(8.6611)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 8.66108512878418}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>ifpic</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>asm</th>\n",
       "      <th>con</th>\n",
       "      <th>eng</th>\n",
       "      <th>idm</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509085</td>\n",
       "      <td>0.916879</td>\n",
       "      <td>-0.866819</td>\n",
       "      <td>0.556730</td>\n",
       "      <td>0.725873</td>\n",
       "      <td>-0.919456</td>\n",
       "      <td>0.588853</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>-0.799702</td>\n",
       "      <td>-0.117813</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>1.462575</td>\n",
       "      <td>0.926437</td>\n",
       "      <td>0.655334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>-0.567655</td>\n",
       "      <td>0.531048</td>\n",
       "      <td>0.513287</td>\n",
       "      <td>-0.737549</td>\n",
       "      <td>0.902894</td>\n",
       "      <td>0.449059</td>\n",
       "      <td>-0.838995</td>\n",
       "      <td>-0.687405</td>\n",
       "      <td>0.540872</td>\n",
       "      <td>2.296487</td>\n",
       "      <td>0.493395</td>\n",
       "      <td>0.730622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.036753</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>0.555130</td>\n",
       "      <td>-1.022523</td>\n",
       "      <td>-0.985355</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>-0.998609</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>0.505114</td>\n",
       "      <td>-0.902389</td>\n",
       "      <td>-0.682143</td>\n",
       "      <td>-0.983619</td>\n",
       "      <td>-1.098656</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.036753</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>0.555130</td>\n",
       "      <td>-1.022523</td>\n",
       "      <td>-0.985355</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>-0.998609</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>0.505114</td>\n",
       "      <td>-0.902389</td>\n",
       "      <td>-0.682143</td>\n",
       "      <td>-0.983619</td>\n",
       "      <td>-1.098656</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.036753</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>0.555130</td>\n",
       "      <td>-1.022523</td>\n",
       "      <td>-0.985355</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>-0.998609</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>0.505114</td>\n",
       "      <td>-0.902389</td>\n",
       "      <td>-0.682143</td>\n",
       "      <td>-0.983619</td>\n",
       "      <td>-1.098656</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  type  ifpic        r1        r2        r3        g1        g2  \\\n",
       "0    1     2      1  0.509085  0.916879 -0.866819  0.556730  0.725873   \n",
       "1   12     2      1 -0.006644  0.899975 -0.567655  0.531048  0.513287   \n",
       "2   18     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       "3   22     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       "4   35     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
       "\n",
       "         g3        b1        b2        b3       asm       con       eng  \\\n",
       "0 -0.919456  0.588853  0.598425 -0.799702 -0.117813  0.055439  1.462575   \n",
       "1 -0.737549  0.902894  0.449059 -0.838995 -0.687405  0.540872  2.296487   \n",
       "2  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       "3  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       "4  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
       "\n",
       "        idm      loss  \n",
       "0  0.926437  0.655334  \n",
       "1  0.493395  0.730622  \n",
       "2 -1.098656  0.035264  \n",
       "3 -1.098656  0.035264  \n",
       "4 -1.098656  0.035264  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = VAE.load_from_checkpoint('C:/Users/Ni Ying/Desktop/data/img_ad_vae_weights.ckpt')\n",
    "trained_model.freeze()\n",
    "dataset = TSDataset('test', cont_vars=hparams.cont_vars, \n",
    "                    cat_vars=hparams.cat_vars,\n",
    "                    lbl_as_feat=True) \n",
    "losses = []\n",
    "# run predictions for the training set examples\n",
    "for i in range(len(dataset)):\n",
    "    x_cont, x_cat = dataset[i]\n",
    "    x_cont.unsqueeze_(0)\n",
    "    x_cat.unsqueeze_(0)\n",
    "    recon, mu, logvar, x = trained_model.forward((x_cont, x_cat))\n",
    "    recon_loss, kld = trained_model.loss_function(x, recon, mu, logvar)\n",
    "    losses.append(recon_loss + trained_model.hparams.kld_beta * kld)\n",
    "    \n",
    "data_with_losses = dataset.df\n",
    "data_with_losses['loss'] = np.asarray(losses)\n",
    "data_with_losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34678179025650024, 0.4900517165660858)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, sigma = data_with_losses['loss'].mean(), data_with_losses['loss'].std()\n",
    "mean, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2)  \n",
    "sns.distplot(data_with_losses['loss'], ax = axes[0], kde = True, rug = True)        # kde 密度曲线  rug 边际毛毯  \n",
    "sns.kdeplot(data_with_losses['loss'], ax = axes[1], shade=True)                     # shade  阴影                         \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 6  # threshold for anomaly, in sigmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  type  ifpic        r1        r2        r3        g1        g2  \\\n",
      "0    1     2      1  0.509085  0.916879 -0.866819  0.556730  0.725873   \n",
      "1   12     2      1 -0.006644  0.899975 -0.567655  0.531048  0.513287   \n",
      "2   18     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
      "3   22     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
      "4   35     2      0 -1.036753 -0.850720  0.555130 -1.022523 -0.985355   \n",
      "\n",
      "         g3        b1        b2        b3       asm       con       eng  \\\n",
      "0 -0.919456  0.588853  0.598425 -0.799702 -0.117813  0.055439  1.462575   \n",
      "1 -0.737549  0.902894  0.449059 -0.838995 -0.687405  0.540872  2.296487   \n",
      "2  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
      "3  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
      "4  0.524007 -0.998609 -0.975355  0.505114 -0.902389 -0.682143 -0.983619   \n",
      "\n",
      "        idm      loss  anomaly  \n",
      "0  0.926437  0.655334    False  \n",
      "1  0.493395  0.730622    False  \n",
      "2 -1.098656  0.035264    False  \n",
      "3 -1.098656  0.035264    False  \n",
      "4 -1.098656  0.035264    False  \n"
     ]
    }
   ],
   "source": [
    "data_with_losses['anomaly'] = data_with_losses['loss'] > (mean + sigma * thresh)\n",
    "print(data_with_losses.head())\n",
    "colors = ['red' if anomaly else 'blue' for anomaly in data_with_losses['anomaly']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fc9810ff08>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies_loss = data_with_losses.loc[data_with_losses['anomaly'], 'loss']\n",
    "normals_loss   = data_with_losses.loc[~data_with_losses['anomaly'], 'loss']\n",
    "plt.hist([normals_loss, anomalies_loss], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'abnormal'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       uid  type  ifpic          r1         r2         r3          g1  \\\n",
      "0  1088916     2      1   97.614978  67.456272  63.780334   97.087358   \n",
      "1       37     2      0    0.057993   0.024396  -0.029042    0.048980   \n",
      "2       42     2      1  212.405175  80.847712 -96.379919  211.349598   \n",
      "3  1088924     2      0    0.057993   0.024396  -0.029042    0.048980   \n",
      "4  1088942     2      1  102.540626  61.393805   9.708157  109.923367   \n",
      "\n",
      "          g2         g3          b1         b2         b3       asm       con  \\\n",
      "0  68.117285  64.699577   90.991269  71.837066  67.974166  0.027085  8.851774   \n",
      "1   0.021508   0.092140    0.010261   0.008832   0.060727  0.000009 -0.011093   \n",
      "2  75.771202 -85.542578  224.618555  55.529670 -70.554195  0.442060  6.478422   \n",
      "3   0.021508   0.092140    0.010261   0.008832   0.060727  0.000009 -0.011093   \n",
      "4  65.996971 -32.987108   93.182573  60.048402 -14.858932  0.025685  3.052300   \n",
      "\n",
      "        eng       idm      loss  anomaly  \n",
      "0  4.346545  0.540460  0.114905    False  \n",
      "1  0.001393  0.000286  0.007562    False  \n",
      "2  2.122618  0.809034  0.349021    False  \n",
      "3  0.001393  0.000286  0.007562    False  \n",
      "4  4.164575  0.631431  0.121053    False  \n"
     ]
    }
   ],
   "source": [
    "data_with_losses_unscaled = data_with_losses.copy()\n",
    "data_with_losses_unscaled[cont_vars] = scaler.inverse_transform(data_with_losses[cont_vars])\n",
    "data_with_losses_unscaled = pd.DataFrame(data_with_losses_unscaled, columns=data_with_losses.columns)\n",
    "print(data_with_losses_unscaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fc99191188>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies_value = data_with_losses_unscaled.loc[data_with_losses_unscaled['anomaly'], ['loss','type']]\n",
    "normals_value = data_with_losses_unscaled.loc[~data_with_losses_unscaled['anomaly'], ['loss','type']]\n",
    "\n",
    "plt.hist([normals_value['type'], anomalies_value['type']], bins=100, stacked=True, color=['blue', 'red'], label=['normal', 'abnormal'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_ts = data_with_losses_unscaled.loc[data_with_losses_unscaled['anomaly'], ('t', 'value')]\n",
    "holidays_ts = data_with_losses_unscaled.loc[data_with_losses_unscaled['holiday'] == 1, ('t', 'value')]\n",
    "print(anomalies_ts.head())\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_with_losses_unscaled['t'], data_with_losses_unscaled['value'], color='blue')\n",
    "ax.scatter(anomalies_ts['t'], anomalies_ts['value'], color='red', label='anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
