{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = Path('C:/Users/Ni Ying/Desktop/data/network_datanew.xlsx')\n",
    "datasets_root = Path('C:/Users/Ni Ying/Desktop/data/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>closeness_centrality</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>degree</th>\n",
       "      <th>clustering</th>\n",
       "      <th>ego_betweenness_centrality</th>\n",
       "      <th>ego_pagerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.037270</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.242580</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>25</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.391487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.230282</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.238747</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>164</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.161289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.198369</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.196286</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid type  betweenness_centrality  degree_centrality  closeness_centrality  \\\n",
       "0    1  pri                0.037270           0.000561              0.242580   \n",
       "1   12  pri                0.000057           0.000157              0.230282   \n",
       "2   18  pri                0.002311           0.003682              0.238747   \n",
       "3   22  pri                0.000003           0.000045              0.198369   \n",
       "4   35  pri                0.000000           0.000022              0.196286   \n",
       "\n",
       "   pagerank  degree  clustering  ego_betweenness_centrality  ego_pagerank  \n",
       "0  0.000120      25    0.016667                    0.976667      0.391487  \n",
       "1  0.000030       7    0.000000                    1.000000      0.469596  \n",
       "2  0.000632     164    0.031423                    0.804976      0.161289  \n",
       "3  0.000013       2    0.000000                    1.000000      0.486486  \n",
       "4  0.000008       1    0.000000                    0.000000      0.500000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dt = pd.read_excel(datafile_path)\n",
    "raw_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = ['betweenness_centrality','degree_centrality','closeness_centrality','pagerank','degree','clustering','ego_betweenness_centrality','ego_pagerank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_data = data[data['type']=='pri']\n",
    "tst_data = pri_data\n",
    "off_data = data[data['type']=='off']\n",
    "plat_data = data[data['type']=='plat']\n",
    "tr_data = pd.concat((off_data, plat_data), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>closeness_centrality</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>degree</th>\n",
       "      <th>clustering</th>\n",
       "      <th>ego_betweenness_centrality</th>\n",
       "      <th>ego_pagerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5719</td>\n",
       "      <td>off</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.173520</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6719</td>\n",
       "      <td>off</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.218409</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7179</td>\n",
       "      <td>off</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.216396</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.407760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7207</td>\n",
       "      <td>off</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.240129</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>29</td>\n",
       "      <td>0.088670</td>\n",
       "      <td>0.786412</td>\n",
       "      <td>0.217646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7257</td>\n",
       "      <td>off</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.183737</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid type  betweenness_centrality  degree_centrality  closeness_centrality  \\\n",
       "0  5719  off                0.000000           0.000022              0.173520   \n",
       "1  6719  off                0.000040           0.000067              0.218409   \n",
       "2  7179  off                0.000410           0.000135              0.216396   \n",
       "3  7207  off                0.001645           0.000651              0.240129   \n",
       "4  7257  off                0.000000           0.000022              0.183737   \n",
       "\n",
       "   pagerank  degree  clustering  ego_betweenness_centrality  ego_pagerank  \n",
       "0  0.000007       1    0.000000                    0.000000      0.500000  \n",
       "1  0.000016       3    0.000000                    1.000000      0.479731  \n",
       "2  0.000040       6    0.066667                    0.933333      0.407760  \n",
       "3  0.000108      29    0.088670                    0.786412      0.217646  \n",
       "4  0.000011       1    0.000000                    0.000000      0.500000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>closeness_centrality</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>degree</th>\n",
       "      <th>clustering</th>\n",
       "      <th>ego_betweenness_centrality</th>\n",
       "      <th>ego_pagerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.037270</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.242580</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>25</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.391487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.230282</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.238747</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>164</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.161289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.198369</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>pri</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.196286</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid type  betweenness_centrality  degree_centrality  closeness_centrality  \\\n",
       "0    1  pri                0.037270           0.000561              0.242580   \n",
       "1   12  pri                0.000057           0.000157              0.230282   \n",
       "2   18  pri                0.002311           0.003682              0.238747   \n",
       "3   22  pri                0.000003           0.000045              0.198369   \n",
       "4   35  pri                0.000000           0.000022              0.196286   \n",
       "\n",
       "   pagerank  degree  clustering  ego_betweenness_centrality  ego_pagerank  \n",
       "0  0.000120      25    0.016667                    0.976667      0.391487  \n",
       "1  0.000030       7    0.000000                    1.000000      0.469596  \n",
       "2  0.000632     164    0.031423                    0.804976      0.161289  \n",
       "3  0.000013       2    0.000000                    1.000000      0.486486  \n",
       "4  0.000008       1    0.000000                    0.000000      0.500000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(tr_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled = tr_data.copy()\n",
    "tr_data_scaled[cont_vars] = scaler.transform(tr_data[cont_vars])\n",
    "tst_data_scaled = tst_data.copy()\n",
    "tst_data_scaled[cont_vars] = scaler.transform(tst_data[cont_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           uid type  betweenness_centrality  degree_centrality  \\\n",
       " 0            1  pri                0.037270           0.000561   \n",
       " 1           12  pri                0.000057           0.000157   \n",
       " 2           18  pri                0.002311           0.003682   \n",
       " 3           22  pri                0.000003           0.000045   \n",
       " 4           35  pri                0.000000           0.000022   \n",
       " ...        ...  ...                     ...                ...   \n",
       " 63656  1817611  pri                0.000000           0.000022   \n",
       " 63657  1817678  pri                0.000000           0.000000   \n",
       " 63658  1817710  pri                0.000000           0.000000   \n",
       " 63659  1817712  pri                0.000000           0.000000   \n",
       " 63660  1817890  pri                0.000000           0.000000   \n",
       " \n",
       "        closeness_centrality  pagerank  degree  clustering  \\\n",
       " 0                  0.242580  0.000120      25    0.016667   \n",
       " 1                  0.230282  0.000030       7    0.000000   \n",
       " 2                  0.238747  0.000632     164    0.031423   \n",
       " 3                  0.198369  0.000013       2    0.000000   \n",
       " 4                  0.196286  0.000008       1    0.000000   \n",
       " ...                     ...       ...     ...         ...   \n",
       " 63656              0.000022  0.000022       1    0.000000   \n",
       " 63657              0.000000  0.000000       0    0.000000   \n",
       " 63658              0.000000  0.000000       0    0.000000   \n",
       " 63659              0.000000  0.000000       0    0.000000   \n",
       " 63660              0.000000  0.000000       0    0.000000   \n",
       " \n",
       "        ego_betweenness_centrality  ego_pagerank  \n",
       " 0                        0.976667      0.391487  \n",
       " 1                        1.000000      0.469596  \n",
       " 2                        0.804976      0.161289  \n",
       " 3                        1.000000      0.486486  \n",
       " 4                        0.000000      0.500000  \n",
       " ...                           ...           ...  \n",
       " 63656                    0.000000      0.500000  \n",
       " 63657                    0.000000      0.000000  \n",
       " 63658                    0.000000      0.000000  \n",
       " 63659                    0.000000      0.000000  \n",
       " 63660                    0.000000      0.000000  \n",
       " \n",
       " [59891 rows x 10 columns],\n",
       "            uid type  betweenness_centrality  degree_centrality  \\\n",
       " 0            1  pri               16.812872           0.531199   \n",
       " 1           12  pri               -0.034107           0.090037   \n",
       " 2           18  pri                0.986547           3.937948   \n",
       " 3           22  pri               -0.058566          -0.032508   \n",
       " 4           35  pri               -0.059777          -0.057017   \n",
       " ...        ...  ...                     ...                ...   \n",
       " 63656  1817611  pri               -0.059777          -0.057017   \n",
       " 63657  1817678  pri               -0.059777          -0.081526   \n",
       " 63658  1817710  pri               -0.059777          -0.081526   \n",
       " 63659  1817712  pri               -0.059777          -0.081526   \n",
       " 63660  1817890  pri               -0.059777          -0.081526   \n",
       " \n",
       "        closeness_centrality  pagerank    degree  clustering  \\\n",
       " 0                  1.943931  0.306100  0.531199    0.145554   \n",
       " 1                  1.810575  0.030095  0.090037   -0.121136   \n",
       " 2                  1.902370  1.887598  3.937948    0.381677   \n",
       " 3                  1.464529 -0.024286 -0.032508   -0.121136   \n",
       " 4                  1.441947 -0.037622 -0.057017   -0.121136   \n",
       " ...                     ...       ...       ...         ...   \n",
       " 63656             -0.686221  0.006342 -0.057017   -0.121136   \n",
       " 63657             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 63658             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 63659             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 63660             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " \n",
       "        ego_betweenness_centrality  ego_pagerank  \n",
       " 0                        1.830233      0.948165  \n",
       " 1                        1.886944      1.289239  \n",
       " 2                        1.412942     -0.057026  \n",
       " 3                        1.886944      1.362989  \n",
       " 4                       -0.543533      1.422001  \n",
       " ...                           ...           ...  \n",
       " 63656                   -0.543533      1.422001  \n",
       " 63657                   -0.543533     -0.761319  \n",
       " 63658                   -0.543533     -0.761319  \n",
       " 63659                   -0.543533     -0.761319  \n",
       " 63660                   -0.543533     -0.761319  \n",
       " \n",
       " [59891 rows x 10 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_data, tst_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          uid  type  betweenness_centrality  degree_centrality  \\\n",
       " 0        5719   off                0.000000           0.000022   \n",
       " 1        6719   off                0.000040           0.000067   \n",
       " 2        7179   off                0.000410           0.000135   \n",
       " 3        7207   off                0.001645           0.000651   \n",
       " 4        7257   off                0.000000           0.000022   \n",
       " ...       ...   ...                     ...                ...   \n",
       " 3767  1808066  plat                0.000000           0.000000   \n",
       " 3768  1808828  plat                0.000000           0.000000   \n",
       " 3769  1809348  plat                0.000000           0.000000   \n",
       " 3770  1823090  plat                0.000000           0.000000   \n",
       " 3771  1825048  plat                0.000000           0.000000   \n",
       " \n",
       "       closeness_centrality  pagerank  degree  clustering  \\\n",
       " 0                 0.173520  0.000007       1    0.000000   \n",
       " 1                 0.218409  0.000016       3    0.000000   \n",
       " 2                 0.216396  0.000040       6    0.066667   \n",
       " 3                 0.240129  0.000108      29    0.088670   \n",
       " 4                 0.183737  0.000011       1    0.000000   \n",
       " ...                    ...       ...     ...         ...   \n",
       " 3767              0.000000  0.000000       0    0.000000   \n",
       " 3768              0.000000  0.000000       0    0.000000   \n",
       " 3769              0.000000  0.000000       0    0.000000   \n",
       " 3770              0.000000  0.000000       0    0.000000   \n",
       " 3771              0.000000  0.000000       0    0.000000   \n",
       " \n",
       "       ego_betweenness_centrality  ego_pagerank  \n",
       " 0                       0.000000      0.500000  \n",
       " 1                       1.000000      0.479731  \n",
       " 2                       0.933333      0.407760  \n",
       " 3                       0.786412      0.217646  \n",
       " 4                       0.000000      0.500000  \n",
       " ...                          ...           ...  \n",
       " 3767                    0.000000      0.000000  \n",
       " 3768                    0.000000      0.000000  \n",
       " 3769                    0.000000      0.000000  \n",
       " 3770                    0.000000      0.000000  \n",
       " 3771                    0.000000      0.000000  \n",
       " \n",
       " [3772 rows x 10 columns],\n",
       "           uid  type  betweenness_centrality  degree_centrality  \\\n",
       " 0        5719   off               -0.059777          -0.057017   \n",
       " 1        6719   off               -0.041620          -0.007999   \n",
       " 2        7179   off                0.126041           0.065528   \n",
       " 3        7207   off                0.685155           0.629235   \n",
       " 4        7257   off               -0.059777          -0.057017   \n",
       " ...       ...   ...                     ...                ...   \n",
       " 3767  1808066  plat               -0.059777          -0.081526   \n",
       " 3768  1808828  plat               -0.059777          -0.081526   \n",
       " 3769  1809348  plat               -0.059777          -0.081526   \n",
       " 3770  1823090  plat               -0.059777          -0.081526   \n",
       " 3771  1825048  plat               -0.059777          -0.081526   \n",
       " \n",
       "       closeness_centrality  pagerank    degree  clustering  \\\n",
       " 0                 1.195088 -0.042286 -0.057017   -0.121136   \n",
       " 1                 1.681831 -0.012560 -0.007999   -0.121136   \n",
       " 2                 1.660005  0.060879  0.065528    0.945626   \n",
       " 3                 1.917356  0.270114  0.629235    1.297711   \n",
       " 4                 1.305868 -0.030000 -0.057017   -0.121136   \n",
       " ...                    ...       ...       ...         ...   \n",
       " 3767             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 3768             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 3769             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 3770             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " 3771             -0.686464 -0.062917 -0.081526   -0.121136   \n",
       " \n",
       "       ego_betweenness_centrality  ego_pagerank  \n",
       " 0                      -0.543533      1.422001  \n",
       " 1                       1.886944      1.333491  \n",
       " 2                       1.724912      1.019221  \n",
       " 3                       1.367824      0.189062  \n",
       " 4                      -0.543533      1.422001  \n",
       " ...                          ...           ...  \n",
       " 3767                   -0.543533     -0.761319  \n",
       " 3768                   -0.543533     -0.761319  \n",
       " 3769                   -0.543533     -0.761319  \n",
       " 3770                   -0.543533     -0.761319  \n",
       " 3771                   -0.543533     -0.761319  \n",
       " \n",
       " [3772 rows x 10 columns])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, tr_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_scaled.to_csv(datasets_root/'sn_ad_train.csv', index=False)\n",
    "tst_data_scaled.to_csv(datasets_root/'sn_ad_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDataset(Dataset):\n",
    "    def __init__(self, split, cont_vars=None, lbl_as_feat=True):\n",
    "        \"\"\"\n",
    "        split: 'train' if we want to get data from the training examples, 'test' for\n",
    "        test examples, or 'both' to merge the training and test sets and return samples\n",
    "        from either.\n",
    "        cont_vars: List of continuous variables to return as features. If None, returns\n",
    "        all continuous variables available.\n",
    "        cat_vars: Same as above, but for categorical variables.\n",
    "        lbl_as_feat: Set to True when training a VAE -- the labels (temperature values)\n",
    "        will be included as another dimension of the data. Set to False when training\n",
    "        a model to predict temperatures.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert split in ['train', 'test', 'both']\n",
    "        self.lbl_as_feat = lbl_as_feat\n",
    "        if split == 'train':\n",
    "            self.df = pd.read_csv(datasets_root/'sn_ad_train.csv')\n",
    "        elif split == 'test':\n",
    "            self.df = pd.read_csv(datasets_root/'sn_ad_test.csv')\n",
    "        else:\n",
    "            df1 = pd.read_csv(datasets_root/'sn_ad_train.csv')\n",
    "            df2 = pd.read_csv(datasets_root/'sn_ad_test.csv')\n",
    "            self.df = pd.concat((df1, df2), ignore_index=True)\n",
    "        \n",
    "        if cont_vars:\n",
    "            self.cont_vars = cont_vars\n",
    "        else:  # if no list provided, use all available\n",
    "            self.cont_vars = ['betweenness_centrality','degree_centrality','closeness_centrality','pagerank','degree','clustering','ego_betweenness_centrality','ego_pagerank']\n",
    "        \n",
    "        # Finally, make two Numpy arrays for continuous and categorical\n",
    "        # variables, respectively:\n",
    "        if self.lbl_as_feat:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            self.cont = self.df[self.cont_vars].copy().to_numpy(dtype=np.float32)\n",
    "            self.lbl = self.df['type'].copy().to_numpy(dtype=np.float32)\n",
    "        #self.cat = self.df[self.cat_vars].copy().to_numpy(dtype=np.int64)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if self.lbl_as_feat:  # for VAE training\n",
    "            return torch.tensor(self.cont[idx])\n",
    "        else:  # for supervised prediction\n",
    "            return torch.tensor(self.cont[idx]), torch.tensor(self.lbl[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63663\n",
      "tensor([-0.0598, -0.0570,  1.1951, -0.0423, -0.0570, -0.1211, -0.5435,  1.4220])\n",
      "tensor([-0.0416, -0.0080,  1.6818, -0.0126, -0.0080, -0.1211,  1.8869,  1.3335])\n",
      "tensor([0.1260, 0.0655, 1.6600, 0.0609, 0.0655, 0.9456, 1.7249, 1.0192])\n",
      "tensor([0.6852, 0.6292, 1.9174, 0.2701, 0.6292, 1.2977, 1.3678, 0.1891])\n",
      "tensor([-0.0598, -0.0570,  1.3059, -0.0300, -0.0570, -0.1211, -0.5435,  1.4220])\n",
      "tensor([-0.0598, -0.0570,  1.3059, -0.0300, -0.0570, -0.1211, -0.5435,  1.4220])\n",
      "tensor([-0.0598, -0.0570,  1.2993, -0.0434, -0.0570, -0.1211, -0.5435,  1.4220])\n",
      "tensor([-0.0408, -0.0325,  1.6541, -0.0156, -0.0325, -0.1211,  1.8869,  1.3630])\n",
      "tensor([-0.0598, -0.0815, -0.6865, -0.0629, -0.0815, -0.1211, -0.5435, -0.7613])\n",
      "tensor([-0.0598, -0.0570,  1.1691, -0.0392, -0.0570, -0.1211, -0.5435,  1.4220])\n"
     ]
    }
   ],
   "source": [
    "ds = TSDataset(split='both', cont_vars=['betweenness_centrality','degree_centrality','closeness_centrality','pagerank','degree','clustering','ego_betweenness_centrality','ego_pagerank'], lbl_as_feat=True)\n",
    "print(len(ds))\n",
    "it = iter(ds)\n",
    "for _ in range(10):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    '''\n",
    "    A single fully connected layer with optional batch normalisation and activation.\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, bn = True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, out_dim)]\n",
    "        if bn: layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    The encoder part of our VAE. Takes a data sample and returns the mean and the log-variance of the \n",
    "    latent vector's distribution.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeds = nn.ModuleList([\n",
    "            nn.Embedding(n_cats, emb_size) for (n_cats, emb_size) in hparams.embedding_sizes\n",
    "        ])\n",
    "        # The input to the first layer is the concatenation of all embedding vectors and continuous\n",
    "        # values\n",
    "        in_dim = sum(emb.embedding_dim for emb in self.embeds) + len(hparams.cont_vars)\n",
    "        layer_dims = [in_dim] + [int(s) for s in hparams.layer_sizes.split(',')]\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(layer_dims[i], layer_dims[i + 1], bn) for i in range(len(layer_dims) - 1)],\n",
    "        )\n",
    "        self.mu = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "        self.logvar = nn.Linear(layer_dims[-1], hparams.latent_dim)\n",
    "    \n",
    "    def forward(self, x_cont):\n",
    "        x = x_cont\n",
    "        h = self.layers(x)\n",
    "        mu_ = self.mu(h)\n",
    "        logvar_ = self.logvar(h)\n",
    "        return mu_, logvar_, x  # we return the concatenated input vector for use in loss fn\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    The decoder part of our VAE. Takes a latent vector (sampled from the distribution learned by the \n",
    "    encoder) and converts it back to a reconstructed data sample.\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "#         self.final_activ = hparams.final_activ\n",
    "        hidden_dims = [hparams.latent_dim] + [int(s) for s in reversed(hparams.layer_sizes.split(','))]\n",
    "        out_dim = sum(emb_size for _, emb_size in hparams.embedding_sizes) + len(hparams.cont_vars)\n",
    "        bn = hparams.batch_norm\n",
    "        self.layers = nn.Sequential(\n",
    "            *[Layer(hidden_dims[i], hidden_dims[i + 1], bn) for i in range(len(hidden_dims) - 1)],\n",
    "        )\n",
    "        self.reconstructed = nn.Linear(hidden_dims[-1], out_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = self.layers(z)\n",
    "        recon = self.reconstructed(h)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        if isinstance(hparams, dict):\n",
    "            hparams = Namespace(**hparams)\n",
    "        self.hparams = hparams\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.stdev = hparams.stdev\n",
    "        self.kld_beta = hparams.kld_beta\n",
    "        self.lr = hparams.lr\n",
    "        self.wd = hparams.weight_decay\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        '''\n",
    "        The reparameterisation trick allows us to backpropagate through the encoder.\n",
    "        '''\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std) * self.stdev\n",
    "            return eps * std + mu\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x_cont = batch\n",
    "        #assert x_cat.dtype == torch.int64\n",
    "        mu, logvar, x = self.encoder(x_cont)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, mu, logvar, x\n",
    "        \n",
    "    def loss_function(self, obs, recon, mu, logvar):\n",
    "#         recon_loss = F.mse_loss(recon, obs, reduction='sum')\n",
    "        recon_loss = F.smooth_l1_loss(recon, obs, reduction='sum')\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp())\n",
    "        return recon_loss, kld\n",
    "                               \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        # The loss function compares the concatenated input vector including\n",
    "        # embeddings to the reconstructed vector\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "\n",
    "        self.log('total_tr_loss', loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('recon_loss', recon_loss.mean(dim=0), on_step=True, prog_bar=True, \n",
    "                 logger=True)\n",
    "        self.log('kld', kld.mean(dim=0), on_step=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        recon, mu, logvar, x = self.forward(batch)\n",
    "        recon_loss, kld = self.loss_function(x, recon, mu, logvar)\n",
    "        loss = recon_loss + self.kld_beta * kld\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, \n",
    "                                weight_decay=self.hparams.weight_decay, \n",
    "                                eps=1e-4)\n",
    "        sch = torch.optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda epoch: 0.95)\n",
    "        return opt\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TSDataset('train', cont_vars=self.hparams.cont_vars, \n",
    "                            lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        dataset = TSDataset('test', cont_vars=self.hparams.cont_vars,\n",
    "                            lbl_as_feat=True)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams = OrderedDict(\n",
    "    run='img_vars_embsz8_latsz32_bsz64_lay64-128-64_ep50',\n",
    "    cont_vars = cont_vars,\n",
    "    embedding_sizes = [(0, 14)],\n",
    "    latent_dim = 32,\n",
    "    layer_sizes = '64,128,64',\n",
    "    batch_norm = True,\n",
    "    stdev = 0.01,\n",
    "    kld_beta = 0.2,\n",
    "    lr = 0.01,\n",
    "    weight_decay = 1e-5,\n",
    "    batch_size = 64,\n",
    "    epochs = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "# Simulate a Namespace with the defined hyperparameters\n",
    "hparams = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VAE(hparams)\n",
    "logger = WandbLogger(name=hparams.run, project='sn_ad', version=hparams.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 22.7 K\n",
      "1 | decoder | Decoder | 20.6 K\n",
      "------------------------------------\n",
      "43.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "43.4 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3455d85f854219a71d5ca6252560f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x8 and 22x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-646c47011310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      \u001b[0mgradient_clip_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                      )\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mtune\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \"\"\"\n\u001b[1;32m--> 848\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_setup_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\tuner\\tuning.py\u001b[0m in \u001b[0;36mtune\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Run learning rate finder:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_lr_find\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_find_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m  \u001b[1;31m# reset logger binding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\tuner\\tuning.py\u001b[0m in \u001b[0;36minternal_find_lr\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minternal_find_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_run_lr_finder_internally\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpick_multiple_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py\u001b[0m in \u001b[0;36m_run_lr_finder_internally\u001b[1;34m(trainer, model)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_lr_finder_internally\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;34m\"\"\" Call lr finder internally during Trainer.fit() \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mlr_finder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlr_finder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(trainer, model, train_dataloader, val_dataloaders, min_lr, max_lr, num_training, mode, early_stop_threshold, datamodule)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                 datamodule=datamodule)\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Prompt if we stopped early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_fit_start'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\accelerators\\cpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# train or test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_training_epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;31m# run train epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[1;31m# ------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_training_batch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[0mbatch_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                         \u001b[1;31m# optimizer step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_tpu\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTPU_AVAILABLE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             \u001b[0musing_lbfgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         )\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[0;32m   1255\u001b[0m             \u001b[1;31m# wraps into LightingOptimizer only for running step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_lightning_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, make_optimizer_step, *args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;31m# make sure to call optimizer_closure when accumulating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[1;34m(self, closure, profiler_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0maccelerator_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    711\u001b[0m                                 \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m                             )\n\u001b[0;32m    715\u001b[0m                             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[1;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_step_and_backward\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[1;31m# lightning module hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'training_step'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mtraining_step_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_logged_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\accelerators\\cpu_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\accelerators\\cpu_accelerator.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, model_step, args)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-1d641f82fb1e>\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mrecon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;31m# The loss function compares the concatenated input vector including\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# embeddings to the reconstructed vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-1d641f82fb1e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx_cont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#assert x_cat.dtype == torch.int64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mrecon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-49eb5a29827c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_cont)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mmu_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mlogvar_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-49eb5a29827c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8 and 22x64)"
     ]
    }
   ],
   "source": [
    "ckpt_callback = pl.callbacks.ModelCheckpoint(filepath='C:/Users/Ni Ying/Desktop/data/sn_ad_vae_weights')\n",
    "# Replace argument logger by None if you don't have a WandB account (and don't want to create one)\n",
    "trainer = pl.Trainer(gpus=None,logger=logger, max_epochs=hparams.epochs, \n",
    "                     auto_lr_find=True, benchmark=True, callbacks=[ckpt_callback],\n",
    "                     gradient_clip_val=1.\n",
    "                     )\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
